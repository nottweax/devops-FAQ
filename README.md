# devops-FAQ

## Linux

### Расскажи, как происходит процесс загрузки ОС linux с момента нажатия кнопки питания. 

- Процесс загрузки системы
    
    Этапы следующие
    
    ![boot-system-img](https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled.png)
    
    1. При включении компьютера цп переходит на адрес биоса и загружает биос.  
    2. Биос, или uefi проходит кучу проверок и согласно своим проверкам носитель информации.  
    3. На носителе находится MBR или GPT где находится загрузчик. Дальше по обстоятельствам. Загрузчик может загружать ось, а может передать управление дальше. 
       Например, если у нас есть несколько систем на нескольких разделах.  
       Под первой частью загрузки подразумевается небольшая часть машинного кода, которая запускает второй загрузчик. Потому что выделяется 446 байт. Там ничего не поместится.   
    4. Итого загрузчик первого этапа загружает загрузчик второго и кладет данные в оперативку. 
       Загрузчик, зная где лежит загрузчик ос, грузит его, и грузит initial ram disk - там лежат модули ядра. Они также являются драйверами, которые необходимы для загрузки всей остальной системы.   
    
    1. Затем ядро берет всё на себя. Инициализация устройств, конфигурирование процессора, памяти
    2. Далее запускается пользовательская среда, процесс init
    

    

    **супер коротко**
    1. загрузка биоса либо UEFI.
    2. биос либо UEFI проверяет работоспособность всех компонентов и запускает бутлоадер, 
       ищет его в  MBR или GPT разделе на диске.
    3. бутлоадер грузит OS.
    4. она уже грузит ядро.
    5. ядро конфигурирует уже всю память, процессор и тд.
    6. ядро запускает init процесс.
    8. запускаются все сервисы.
    9. логин в систему.
    7. запускаются скрипты оболочки юзера аля .bashrc, .zshrc, zprofile и тд.
  
---

### Что за процессы в Linux c PID 0 и 1

- Ответ
    Процесс с PID 0 - это процесс swap (или идл процесс).
    
    Этот процесс не выполняет никаких задач, он является бездействующим.
    Процессор переходит к выполнению процесса 0, когда нет других активных процессов для выполнения.
    
    
    Процесс с PID 1 - это init процесс (или systemd в современных дистрибутивах Linux).
    
    Это первый процесс, который запускается во время загрузки системы после ядра Linux.
    Он является родительским процессом для всех остальных процессов в системе.
    init процесс отвечает за запуск различных системных служб и демонов при загрузке.
    Если init процесс завершается, это приводит к остановке всей системы.

  ---
  ### Какие основные части компоненты включает в себя система на базе дистрибутива linux? 

- Написать ответ
  1. **Начальный загрузчик (GRUB)**  
     GRUB (Grand Unified Bootloader) — это программа, которая отвечает за загрузку операционной системы. Она выполняется на этапе начальной загрузки и предоставляет выбор операционных систем или конфигураций для загрузки ядра.

  2. **Ядро Linux**  
    Ядро — это центральная часть операционной системы. Оно управляет ресурсами компьютера, такими как процессор, память и устройства ввода-вывода. Ядро выполняет важнейшие функции, включая управление процессами, памятью и взаимодействие с аппаратным обеспечением.

  3. **Демоны**  
   Демоны — это фоновые процессы, которые работают в системе и выполняют различные задачи без вмешательства пользователя. Примеры: `cron` (планировщик задач), `sshd` (управление удалёнными соединениями).

  4. **Командная оболочка (Shell)**  
   Оболочка — это интерфейс между пользователем и операционной системой. Она позволяет вводить команды и запускать программы. Примеры командных оболочек: `bash`, `zsh`, `fish`.

  5. **Утилиты командной оболочки**  
   Это набор команд и программ, которые выполняются из командной строки. Примеры таких утилит: `ls` (список файлов), `cp` (копирование файлов), `grep` (поиск текста).

  6. **Графический сервер**  
   Графический сервер, такой как [X.org](http://x.org), управляет графическим интерфейсом, видеокартой, монитором, мышью и другими устройствами ввода-вывода, необходимыми для отображения и взаимодействия с пользователем.

  7. **Среда рабочего стола**  
   Среда рабочего стола — это графический интерфейс, предоставляющий пользователю доступ к утилитам и инструментам операционной системы. Примеры: KDE, GNOME, Xfce, Cinnamon. Они включают в себя различные программы, такие как файловые менеджеры, панель задач и другие утилиты.

  8. **Программы рабочего стола**  
   Программы рабочего стола — это приложения, которые запускаются в рамках среды рабочего стола, такие как текстовые редакторы, браузеры, почтовые клиенты и файловые менеджеры, специфичные для каждой среды.

---
### Что такое ядро, initramfs, загрузчик?

- Ответ
    
    **Ядро** - это самый низкий уровень программного обеспечения, которое взаимодействует с аппаратными средствами компьютера. Оно отвечает за взаимодействие всех приложений, работающих в пространстве пользователя вплоть до физического оборудования.
    
    **Initramfs** - основная цель предоставить пользователю его файлы, которые размещены в файловой системе. То есть для ядра нужно найти, примонтировать файловую систему и предоставить пользователю. 
    
    **Загрузчик** операционной системы — системное программное обеспечение, обеспечивающее загрузку операционной системы непосредственно после включения компьютера (процедуры POST) и начальной загрузки.

  ---

  ### Зачем нужна система инициализации? Какие системы инициализации используются в современных дистрибутивах? (2 - 5 штук) (init)

- Ответ
    
    В операционной системе Linux и других системах семейства Unix после завершения загрузки ядра начинается инициализация Linux системы, сервисов и других компонентов. За это отвечает процесс инициализации, он запускается ядром сразу после завершения загрузки, имеет PID 1, и будет выполняться пока будет работать система.
    
    За время развития операционных систем были созданы различные системы инициализации Linux. В разных дистрибутивах использовались разные системы
    
    Есть init. Это первый процесс, родительский процесс, которые все процессы запускает. Проверка, монитрование файловых систем, запуск служб.
    
    Есть три его варианты работы
    
    **System V init (SysV)**
    
    Это загрузка, основанная на уровне запуска. Обычно их семь. Ну там включение, выключение, режим восстановления и тп.
    
    То есть процесс инициализирует на одном из уровней запуска системы
    
    **SystemD**
    
    Родительский процесс, который запускает инициализацию в ускоренном режиме за счет параллельного запуска задач. Ускоренный режим достигается за счет особенностей работы процессора. И если они позволяют, запускает инициализацию параллельно.
    
    **Upstart**
    
    Здесь запускаются скрипты инициализации, отслеживает события, и реагирует на них. Более гибкий процесс инициализации. Если какая-то служба не запустилась, или вдруг упала, то апстарт это отследит и запустит повторно.
    
---

### Что такое systemd и init ? В чем основное преимущество первого над вторым ?

- Ответ
    И то, и то система инциализации.
    
    В чём конкретно преимущества для меня systemd над init:
    
    - Параллельный старт процессов, в отличие от init
    - Запуск системы с ним быстрее происходит.
    - Не нужно городить костыли на баше — использую простенький
    шаблон для юнитов, в отличие от баш портянки.
    - Не нужно городить километровые пайпы для чтения нужной информации из логов — для всего есть человекопонятные опции;
    - Автоматический рестарт юнитов при падении — не нужно плясать с бубном вокруг ряда сервисов, если выпал один промежуточный;
    - Простая и понятная настройка всего — несколько конфигов (а не тонны, раскиданные по всей системе, как было в легаси) с парами
    ключ=значение;
    - Хорошая документированность (я не говорю, что легаси-набор плохо документирован, я лишь говорю, что systemd не уступает);
    - Он не только загрузчик, но и система инициализирующая демоны
    
---
### Опишите, что происходит (с точки зрения процессов), при выполнении любой команды в консоли, например:
`$ ls -l` 

- **Ответ**
    
    При выполнении команды в консоли происходит системный вызов fork(), в результате которого создаётся копия процесса консоли, затем копия процесса выполняет команду с помощью системного вызова exec(). 
    
    После выполнения команды, копия процесса выполняет системный вызов exit(), в результате которого оригинальному процессу консоли отправляется сигнал SIGCHLD (сообщающий о том, что дочерний процесс завершён). 
    
    Во время работы копии процесса, оригинальный процесс находится в ожидании из-за системного вызова wait().
    

---
### Как посмотреть нагрузку на диски?

- Ответ
    
    Установить утилиту `sysstat`, проверить нагрузку на диски `iostat -xtc`.  
    Использовать утилиту `iotop`, которая показывает процессы, которые активно используют диск.  
    Использовать `dstat` - утилита, которая выводит раз в какое-то время статистику по системным ресурсам. В целом более удобная замена таких утилит как vmstat, iostat, ifstat
    

---

### В чем разница между объявлением переменной `export VAR="VALUE"` и `VAR="VALUE"` в bash?

- Ответ
    
    При объявлении переменной через **export** - переменная будет доступна в любых других процессах. 
    
    При обычном объявлении переменной - переменная будет доступна только в запущенном процессе.
    

---

### Что значит `$@`, `$!`, `$?`, `$$` в bash?

- Ответ
    
    `$@` - показывает все параметры переданные скрипту.  
    `$!` - показывает pid последнего процесса, которая оболочка запустила в фоновом режиме.  
    `$$` - показывает текущий pid процесса.  
    `$?` - показывает с каким кодом завершилась последняя выполненная функция. 0 - успешное выполнение.

    

---


### Как выполнить фильтрацию вывода команды, чтобы на экран были выведены только ошибки (STDERR), игнорируя STDOUT?

- Ответ
    
    ```bash
    cmd 2>&1 >/dev/null | grep pattern
    ```
    

---

### При перенаправлении команд (command1 | command2 ) перенаправляется только stdout. Как сделать так, чтобы stderr тоже перенаправлялся?  

- Ответ
    Либо использовать перенаправление. То есть перенаправляется второй файловый дескриптор туда, куда направлен stdout:  
    `command1 2>&1 | command2`  

    Либо использовать более укороченную версию:    
    `command1 |& command2`  


---
### Как работает sudo? Для чего она используется?

- Ответ
    
    
    Sudo позволяет подменить пользователя и выполнить команду от его имени. 
    Расшифровывается именно так - **s**ubstitute **u**ser and **do**
    
    По умолчанию выполнение команды происходит от имени суперпользователя.
    
    Например, вот эта команда
    
    ```bash
    sudo whoami
    ```
    
    И вот эта
    
    ```bash
    sudo -u swfuse whoami
    ```
    
    Будет отличаться результатом.
    
    Можно просмотреть какие полномочия есть с помощью команды:
    
    ```bash
    sudo -l
    ```
    

---
### Что такое userspace, kernelspace? Чем они отличаются?

- Ответ
    
    Под **пользовательским** пространством понимается весь код операционной системы, который находится вне ядра. 
    
    Большинство Unix-подобных операционных систем (включая Linux) поставляются с разнообразными предустановленными утилитами, средствами разработки и графическими инструментами — это все приложения пространства пользователя.
    
    Все пользовательские приложения (и контейнеризированные и нет) при работе используют различные данные, но где эти данные хранятся?
    
     Какие-то данные поступают из регистров процессора и внешних устройств, но чаще они хранятся в памяти и на диске. Приложения получают доступ к данным, выполняя специальные запросы к ядру — системные вызовы. Например, такие как выделение памяти (для переменных) или открытие файла. В памяти и файлах часто хранится конфиденциальная информация, принадлежащая разным пользователям, поэтому доступ к ним должен запрашиваться у ядра с помощью системных вызовов.
    
    Ядро обеспечивает абстракцию для безопасности, оборудования и внутренних структур данных. Например, системный вызов open() используется для получения дескриптора файла в Python, C, Ruby и других языках программирования. Вряд ли бы вы хотели, чтобы ваша программа работала с XFS на уровне битов, поэтому ядро предоставляет системные вызовы и работает с драйверами. Фактически этот системный вызов настолько распространен, что является частью библиотеки POSIX .
    
    [https://habr.com/ru/company/otus/blog/565832/](https://habr.com/ru/company/otus/blog/565832/)
    
- Краткое определние
    - **Пользовательское пространство** представляющее собой набор местоположений, в которых выполняются обычные пользовательские процессы (т. е. все, кроме ядра). Роль ядра состоит в том, чтобы управлять приложениями, работающими в этом пространстве, от взаимодействия друг с другом и с машиной.
    - **Пространство ядра** , то есть место, где хранится и выполняется код ядра.
    
    Пользовательское пространство имеет доступ к ограниченной памяти, ядро имеет всю память.
    
    И чтобы работать приложения взаимодествуют через интерфейс, которое называется системным вызовом.
    

---
### Что такое системные вызовы? Зачем они нужны и как они работают? Какие системные вызовы знаешь (5-10)

- Ответ
    
    **Системный вызов** — это то, посредством чего код приложения, выполняющегося в пользовательском режиме, запрашивает службу, предоставляемую кодом, который выполняется в режиме ядра.
    
    **read** - чтение из файлового дескриптора.
    
    **open** - открывающий и по возможности создающий файл или устройство
    
    **close -** закрыть файловый дескриптор
    
    **access -** проверка пользовательских привелегий для этого файла
    
    **mmap** - служит для отображения предварительно открытого файла (например, с помощью системного вызоваа open()) в адресное пространство вычислительной системы
    
    Команда для вывода всех системных вызовов во время исполнения программы:
    ```bash
    strace -c ls
    % time     seconds  usecs/call     calls    errors syscall
    ------ ----------- ----------- --------- --------- ----------------
      0.00    0.000000           0         4           read
      0.00    0.000000           0         5           write
      0.00    0.000000           0         6           open
      0.00    0.000000           0         9           close
      0.00    0.000000           0         7           fstat
      0.00    0.000000           0        18           mmap
      0.00    0.000000           0        10           mprotect
      0.00    0.000000           0         2           munmap
      0.00    0.000000           0         3           brk
      0.00    0.000000           0         2           rt_sigaction
      0.00    0.000000           0         1           rt_sigprocmask
      0.00    0.000000           0         2           ioctl
      0.00    0.000000           0         6         6 access
      0.00    0.000000           0         1           execve
      0.00    0.000000           0         2           getdents
      0.00    0.000000           0         1           getrlimit
      0.00    0.000000           0         1           arch_prctl
      0.00    0.000000           0         1         1 futex
      0.00    0.000000           0         1           set_tid_address
      0.00    0.000000           0         1           openat
      0.00    0.000000           0         1           set_robust_list
    ------ ----------- ----------- --------- --------- ----------------
    100.00    0.000000                    84         7 total
    
    ```

    
---

### Где можно найти информацию о конкретном системном вызове?

- Ответ
    
    `man 2 <syscall>`
    
    Но нужно будет предварительно поставить пакет `man-pages`
    
    ```
    sudo apt install manpages-dev manpages-posix-dev
    ```
    

---

### Что делает команда kill?

- Ответ
    
    Назначение команды kill - отправить определенный сигнал процессу.
    По умолчанию используется сигнал SIGTERM.

    А вот все  **сигналы** можно глянуть через kill -l, они нужны для взаимодействия между процессами 
    
    ```
    root@swfuse:~# kill -l
     1) SIGHUP       2) SIGINT       3) SIGQUIT      4) SIGILL       5) SIGTRAP
     6) SIGABRT      7) SIGBUS       8) SIGFPE       9) SIGKILL     10) SIGUSR1
    11) SIGSEGV     12) SIGUSR2     13) SIGPIPE     14) SIGALRM     15) SIGTERM
    16) SIGSTKFLT   17) SIGCHLD     18) SIGCONT     19) SIGSTOP     20) SIGTSTP
    21) SIGTTIN     22) SIGTTOU     23) SIGURG      24) SIGXCPU     25) SIGXFSZ
    26) SIGVTALRM   27) SIGPROF     28) SIGWINCH    29) SIGIO       30) SIGPWR
    31) SIGSYS      34) SIGRTMIN    35) SIGRTMIN+1  36) SIGRTMIN+2  37) SIGRTMIN+3
    38) SIGRTMIN+4  39) SIGRTMIN+5  40) SIGRTMIN+6  41) SIGRTMIN+7  42) SIGRTMIN+8
    43) SIGRTMIN+9  44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13
    48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12
    53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9  56) SIGRTMAX-8  57) SIGRTMAX-7
    58) SIGRTMAX-6  59) SIGRTMAX-5  60) SIGRTMAX-4  61) SIGRTMAX-3  62) SIGRTMAX-2
    63) SIGRTMAX-1  64) SIGRTMAX
    ```

---

### Что такое процесс? Что такое тред? В чем заключаются их главные отличия?

- Ответ
    
    **Процесс** - это исполняемая программа. Когда программист пишет программу и выполняет ее, эта программа становится процессом. Он выполняет задачи в соответствии с инструкциями программы.
    
    **Процесс** - это экземпляр выполняемой компьютерной программы. 
    **Поток** - это компонент процесса, который является самой маленькой исполнительной единицей.
   Ключевая разница
    
    - Процесс означает, что программа выполняется, а поток означает сегмент процесса.
    - Процесс не является легковесным, тогда как потоки - легковесными.
    - Процессу требуется больше времени для завершения, а потоку требуется меньше времени для завершения.
    - Процесс требует больше времени для создания, тогда как поток требует меньше времени на создание.
    - Процессу, требуется больше времени для переключения контекста, тогда как потокам требуется меньше времени для переключения контекста. 
    - **Процесс в основном изолирован, тогда как потоки разделяют память.**
    - Процесс не обменивается данными, а потоки обмениваются данными друг с другом.

---
### Где в linux хранится информация о процессах?

- Ответ
    
    Директория `proc/PID`
    
    Информация о процессах хранится в директориях /proc/N, где N — числовой идентификатор процесса. В этой директории содержатся различные псевдо-файлы, которые содержат информацию о самом процессе и связанном с ним окружении.
    
    **/proc/N/cmdline** — Содержимое командной строки, которой был запущен процесс.
    
    **/proc/N/environ** — Описание окружения, в котором работает процесс. Оно может быть полезно для просмотра содержимого окружения, если вам надо, например, посмотреть, была ли установлена переменная окружения перед запуском программы.
    
    **/proc/N/exe** — Символическая ссылка на выполнимый файл запущенной программы.
    
    **/proc/N/limits** — Лимиты на использование системных ресурсов, актуальные для работающего процесса.
    
    **/proc/N/mounts** — Список смонтированных ресурсов, которые доступны процессу
    
    **/proc/N/status** — Статус работающей программы. Он включает в себя такую информацию как идентификатор родительского процесса, статус самого процесса, его название, его идентификатор, идентификатор пользователя и группы, группы, в которые входит владелец процесса, сколько потоков использует процесс, сколько памяти он использует и так далее.
    
    В этой же директории содержится несколько псевдо-директорий:
    
    **/proc/N/cwd** — Текущая директория для процесса. Представлена символической ссылкой на директорию. Если рабочая директория для процесса изменится, изменится и ссылка.
    
    **/proc/N/fd** — Файловые дескрипторы, которые используются процессом. Для программы bash, например, там по умолчанию будут дескрипторы 0, 1, 2 и 255, указывающие на виртуальный терминал, в котором запущен процесс, например, /dev/pts/6.
    
    **/proc/N/fdinfo** — Информация о файловых дескрипторах. Каждый файл в этой директории содержит поля pos (позиция курсора), flags (флаги, с которыми этот дескриптор был открыт) и mnt_id (идентификатор точки монтирования из списка, содержащегося в файле /proc/N/mountinfo)
    
    **/proc/N/root** — Символическая ссылка на директорию, которая для данного процесса является корневой
    
    **/proc/N/net** — Сетевые системные ресурсы и их параметры, действующие для конкретного процесса.
    

---
### Приложение пишет в логи too many opened files, как это диагностировать?  
- Ответ  
  Сначала проверить лимиты для данного процесса:    
  `grep "Max open files" /proc/PID/limits`   

  Также можно посмотреть лимиты для текущего пользователя:      
  `ulimit -n`    

  Имеет смысл посмотреть лимиты systemd.  
  Что-то типа по пути: `/etc/systemd/system/<service_name>.service`   
  Можно найти такие строчки:
  ```
  [Service]
  LimitNOFILE=10
  ```  

  Также можно заглянуть в лимиты по пути `/etc/security/limits.conf`, пример вывода:
  ```
  *           hard    nofile     65535
  *           soft    nofile      8192       # Required for certain games to run.
  ```

  Также пожно глянуть сколько вообще открыто файлов процессом.    
  `lsof -p PID`  

  Через `strace` процесса можно глянуть какие процессы открываются, и, возможно, не закрываются.  
  `strace -e trace=open,close -p PID`   
  

---

### Представлен вывод команды *top*. Что означает каждая запись в выводе?

```bash
top - 10:44:36 up 91 days, 19:29,  7 users,  load average: 0,00, 0,02, 0,05
Tasks: 156 total,   1 running, 155 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0,0 us,  1,5 sy,  0,0 ni, 96,9 id,  0,0 wa,  0,0 hi,  0,0 si,  1,5 st
KiB Mem : 12137392 total,  6227844 free,  1117728 used,  4791820 buff/cache
KiB Swap:        0 total,        0 free,        0 used. 10090148 avail Mem
```

- Ответ
    
    top - утилита
    
    10:44:36 — время системы
    
    up - сколько система работает с момента последнего запуска
    
    7 user - количество авторизованных юзеров в системе
    
    load average: 0.00, 0.02, 0.05 - параметр средней нагрузки на систему за период времени 1 минута, 5 минут, 15 минут
    
    156 total - всего процессов в системе
    
    1 running - количество процессов в работе
    
    155 sleeping - ожидание процесса или сигнала
    
    0 stopped - количество приостановленных процессов сигналом STOP или выполнение трассировки
    
    0 zombie -  количество зомби-процессов, которые завершили своё выполнение, но присутствующие в системе, чтобы дать родительскому процессу считать свой код завершения.
    
| параметр                    |   описание                                                                                                                                                                                                                                             |
|-----------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
|us (user)                    |Использование процессора пользовательским процессами                                                                                                                                                                                                    |
|sy (system)                  |Использование процессора системным процессами                                                                                                                                                                                                           |
|ni (nice)                    |Использование процессора процессами с измененным приоритетом с помощью команды nice                                                                                                                                                                     |
|id (idle)                    |Простой процессора. Можно сказать, что это свободные ресурсы                                                                                                                                                                                            |
|wa (IO-wait)                 |Время на простой, то есть ожидания переферийных устройств ввода вывода                                                                                                                                                                                  |
|hi (hardware interrupts)     |Показывает сколько процессорного времени было потрачено на обслуживание аппаратного прерывания. (Аппаратные прерывания генерируются аппаратными устройствами. Сетевыми картами, клавиуатурами, датчиками, когда им нужно о чем-то просигнализировать цп.|
|si (software interrupts)     |Показывает сколько процессорного времени было потрачено на обслуживание софтверного прерывания. Фрагмент кода, вызывающий процедуру прерывания                                                                                                          |
|st (stolen by the hypervisor)|Показывает сколько процессорного времени было «украдено» гипервизором. Для запуска виртуальной машины, или для иных нужд                                                                                                                                |


    
    **KiB Mem** - количество оперативной памяти в кибибайтах (кратно 1024): *7106404 total* -- всего доступно оперативной памяти в системе, *306972 free* -- свободно оперативной памяти для использования, *3127144 used* -- использовано оперативной памяти, *3672288 buff/cache* -- буферизовано/закешировано оперативной памяти.
    
    **KiB Swap** - количество swap-памяти в кибибайтах (кратно 1024), которые выделено на диске: *8191996 total* - всего выделено swap-памяти, *8191996 free* - свободно swap-памяти *0 used* - использовано swap-памяти, *3270520 avail Mem* - доступно для использования swap-памяти.
    

---

### Что показывает статус процессов? Какие статусы используются в linux?

- Ответ
    
    ```bash
    R - процесс исполнется, или ждет своей очереди на исполнение
    S - прерываемый сон - процесс ожидает определенного события или сигнала. 
    Нужен, когда процесс нельзя завершить (чтение из файла), ядро переводит на ожидание.
    Ожидать данные от сетевого соединения
    D - непрерывное ожидание, сон. Ждем сигнал от аппаратной части.
    T - остановка процесса, посылаем сигнал STOP. В этом состоянии процессу запрещено выполняться
    Чтобы вернуть к жизни нужно послать CONT
    При завершении процесса он становится зомби
    Z(zombie) - зомби это процесс, который закончил выполнение, но не передал родительскому процессу
    свой код возвращения. Процесс в этом состоянии игнорирует kill. 
    Родитель получает код, и освобождает структуру ядра, которое относится к процессу
    Бывает еще когда родительский умирает раньше дочернего. Процесс становится сиротой. 
    ```
    

---
 #### Процесс создания зомби-процесса

    Зомби-процесс — это процесс, который завершился, но его статус завершения не был считан родительским процессом. Рассмотрим, как происходит создание зомби-процесса:

    1. Родительский процесс (например, оболочка) создаёт дочерний процесс для выполнения команды в скобках.
    2. Внутри этого дочернего процесса запускается команда `sleep 1` в фоновом режиме.
    3. Сразу после этого выполняется команда `exec /bin/sleep 10`, которая заменяет дочерний процесс на `sleep 10`.
    4. Когда `sleep 1` завершает своё выполнение (через 1 секунду), его родительский процесс уже не может обработать его завершение, так как был заменён на команду `sleep 10`.
    5. В результате, процесс `sleep 1` становится **зомби-процессом**, ожидая, пока его статус завершения будет считан. Однако, этого не происходит, потому что родительский процесс уже выполняет другую программу — `sleep 10`.

    Зомби-процесс будет существовать до тех пор, пока не завершится команда `sleep 10` (через 10 секунд), после чего родительская оболочка сможет обработать завершение всей составной команды. 

    Это происходит потому, что команда `exec` заменяет текущий процесс на другой без создания нового процесса, и, следовательно, не может корректно обработать завершение предыдущего дочернего процесса.
    
    #### Интересная тонкость
    
    Каждый процесс, при завершении, временно становится зомби до тех пор, пока родительский процесс не считает его статус завершения. Это совершенно нормальное поведение системы, и короткоживущие зомби-процессы не представляют проблемы.
    
    Однако, ошибки программирования могут привести к накоплению **необрабатываемых зомби-процессов** — процессов, которые завершились, но их статус не был считан родительским процессом. Это может негативно сказаться на работе системы, так как зомби-процессы продолжают занимать записи в таблице процессов.




---

### Чем опасны зомби процессы, какие проблемы они могут создать?

- Ответ
    
    Зомби не занимают памяти (как [процессы-сироты](https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81-%D1%81%D0%B8%D1%80%D0%BE%D1%82%D0%B0)
    ), но блокируют записи в таблице процессов, размер которой ограничен для каждого пользователя и системы в целом.
    
    При достижении лимита записей все процессы пользователя, от имени которого выполняется создающий зомби родительский процесс, не будут способны создавать новые дочерние процессы. Кроме этого, пользователь, от имени которого выполняется родительский процесс, не сможет зайти на консоль (локальную или удалённую) или выполнить какие-либо команды на уже открытой консоли (потому что для этого командный интерпретатор *sh* должен создать новый процесс)
    
    Иногда, если родительский процесс выполняется от имени суперпользователя, для освобождения записей (перезапуска процесса) может потребоваться перезагрузка (причём зачастую — только аппаратным рестартом). Некоторые операционные системы (например, [Sun Solaris](https://ru.wikipedia.org/wiki/Solaris)
    ) при возникновении такой ситуации аварийно завершают часть выполняющихся процессов, восстанавливая работоспособность системы.
    

---
### Можно ли завершить зомби процесс с помощью SIGKILL?
 - Ответ
    Нет, не может. Поскольку зомби процесс уже завершен. И не может принимать сигналов. И тут зомби ожидает что родительский процесс считает код завершения с помощью системного вызова wait.

---

### Что такое SIGCHLD? В какой ситуации процесс может его получить?

- Ответ
    
    В POSIX-системах SIGCHLD — сигнал, посылаемый при изменении статуса дочернего процесса (завершён, приостановлен или возобновлен).
    
    Допустим дочерний процесс завершил выполнение и все
    

---

### Что такое файловый дескриптор, какая информация в нем бывает?

- Ответ
    
    *Файловый дескриптор*
     - неотрицательное целое число, которое используется в интерфейсе между пространством пользователя и пространством ядра (kernel) для идентификации ресурсов файла / сокета. Когда создаётся новый поток ввода-вывода, ядро возвращает процессу, создавшему поток ввода-вывода, его файловый дескриптор.
     Важно отметить, что файловые дескрипторы не ограничиваются только файлами. 
     Они также могут ссылаться на каталоги, сокеты, каналы (pipes), устройства ввода-вывода и даже некоторые специфические для процесса ресурсы, такие как файлы процесса и области памяти.
     Операционная система автоматически создает три файловых дескриптора для каждого процесса: 0 (стандартный ввод), 1 (стандартный вывод) и 2 (стандартный вывод ошибок).
    

---
### Для чего нужны сигналы? Какие сигналы используются чаще всего? (5 - 10 штук)

- Ответ
    
    Это уведомление процесса о наступившем событии. Также это способ взаимодйествия между процссами.
    `SIGTERM (15)` - запрос на "мягкое завершение процесса.  
    `SIGKILL (9)` - принудительное завершение процесса.  
    `SIGINT (2)` - прерывание процесса. (Например нажатие Ctrl-C)  
    `SIGSTOP (10)` - приостановка процесса.   
    `SIGCONT (18)` - возобновить работу процесса.   
    `SIGHUP (1)` - перезагрузка конфигурации (например можно так сделать релоад nginx)   

    Сигналы `SIGKILL` и `SIGSTOP` нельзя перехватить, блокировать или игнорировать.   





---

### Какой сигнал получит активный процесс при нажатии Ctrl+C в консоли?

- Ответ
    
    SIGINT (от англ. signal и interrupt — прервать) — сигнал, применяемый в POSIX-системах для остановки процесса пользователем с терминала.
    

---
### Какие сигналы не могут быть проигнорированы?  
- Ответ  
    SIGSTOP - принудительная остановка процесса    
    SIGKILL - немедленное завершение процесса    

---

### Что такое load average? Что показывает эта метрика? Почему load average состоит из трёх значений?

- Ответ
    
    Часто говорят что это средняя загрузка процессора или нагрузка системы, или какие-то циферки.
    Узнать значение la можно разными способами. Например, uptime, top, и другими командами.
    
    Принято считать, что какое-то стабильное значение этих цифр отражает стабильное поведение системы. 
    Появление всплеска может означать появление проблемы в системе.  Что-то идет не так, копятся процессы.
    Цифры обозначают нагрузку за определенный период времени. 1, 5 и 15 минут. (Это важно учесть, это все рассчитывается для предыдущего времени. И когда вы заходите на сервер спустя минуту - там может ничего не быть)
    
    
    **Определение LA по сути - эта цифра показывает количество процессов в статусе d r (ожидание, запущено соответственно)**
    А дальше уже всё будет зависеть от ситуации.
    Допустим у нас сервер есть где постоянно на диски пишутся резервные копии. Там LA будет высокая скорее всего. Просто потому что есть процессы в статусе d, которые копятся из-за того, что диск занят. 
    Но на работу системы в целом это может не влиять вообще.

    Если процессов скопилось много там, где это не ожидается, ну там сервера с сайтами, базами данных, с php-fpm, nginx и прочим таким, то смотрим через `top -cHi -d1` что там именно скопилось. 
    И в таких вот случаях сервер может тупить, ибо будут копиться процессы в статусе r. Из-за чего работа сервера будет медленной. Даже по ssh иногда не зайти будет.


    **если коротко** это кол-во процессов и операций ввода/вывода которые находяться в ожидание 
    процессорного времени(исполнения процессором) за 1, 5, 15 минут
    
    

---
### Можно ли сделать так, чтобы пользователи могли получать информацию только о своих процессах?

- Ответ
    
    Да, можно, за это отвечает параметр hidepid
    
    ```bash
    myserver : ~ [0] # cat /proc/mounts | grep proc
    proc /proc proc rw,nosuid,nodev,noexec,relatime,hidepid=2 0 0
    ```
    

---

### Где в системе можно посмотреть сводку по текущему потреблению памяти?

- Ответ
    
    ```bash
    free -m
    ```
    ```
                   total        used        free      shared  buff/cache   available
    Mem:            3923         309         231           2        3382        3318
    Swap:              0           0           0
    ```
    Эта утилита не показывает физическое количество памяти.   
    Она показывает сколько памяти доступно в системе.  
    То есть физически сколько заняло ядро.  

    `total` - 3923 мегабайт - Она показывает сколько памяти у нас в системе.    
    `used` - 309 мегабайт - сколько у нас памяти занимают исполняемые процессы.     
    `free` - 231 мегабайт - ненужная в данный момент память. То есть если надо будет системе - она ее займет.  
    `shared` - 2 мегабайта - shared память для межпроцессорного взаимодействия. Чтобы поделиться памятью из одного процессора в другой.   
    `buff/cache` - буффер - память для компоновки данных. Страничный кэш - это то, с помощью чего мы например можем файлы открывать.   


    **Почему линукс съедает память?**
    Потому что процесс который запрашивает данные из файла на диски - он данные выгружает в оперативную память.   
    Чем больше процессов просит данных - тем больше кэша, свободной памяти становится меньше.   
    Однако, единожды загруженный файл в кеш - может там остаться даже если приложение, которое это инициировало - завершилось.  
    Поскольку операции доступа до диска это дорогие по времени операции.  
    И ядро считает, что стоит сохранить какие-то из данных, не чистить их сразу. На тот случай, если кому-то еще эти данные понадобятся. 

    Итого свободная память - это та память которая ни нужна ни для кэша, ни для чего-то ещё.  
    `available` - 3381 мегабайт может быть доступно в случае необходимости.  
    Если available нет, то его в примерном виде можно посчитать так: free + 70% от кэша.   
    Ибо не во всех дистрибутивах этот показатель есть.  

    **Какие ситуации будут указывать на возможную проблему?**  
    * Available память или ( free -/+ buffers/cache ) близки к нулю или очень маленькое значение.  
    * В логах ядра есть сообщения `OutOfMemory`. (`dmesg -T | grep out of memory`)

---
### Как работает оом киллер и для чего нужен? Out of memory, oom

- Ответ
    
    Когда на вашем Linux-компьютере заканчивается память, ядро вызывает Убийцу нехватки памяти (OOM) для освобождения памяти. Это часто встречается на серверах, на которых запущен ряд процессов с интенсивным использованием памяти.
    
    Оом киллер освобождает память для спасения системы, но чтобы процессы освобождаемые были наименее важны для системы.
    
    У нас не только физическая и виртуальная память может закончиться. А если процесс потребляет страницу определенного размера, то могут быть не очень хорошие вещи.
    
    Ядро Linux дает оценку каждому запущенному процессу, называемому **oom_score**, которая показывает, насколько вероятно, что он будет остановлен в случае нехватки доступной памяти. 
    
    Оценка пропорциональна количеству памяти, используемой процессом. Оценка - 10% процентов памяти, используемой процессом. Таким образом, максимальная оценка составляет 100% x 10 = 1000.
    
    [https://github.com/hightemp/docLinux/blob/master/articles/Linux OOM killer - выживание.md](https://github.com/hightemp/docLinux/blob/master/articles/Linux%20OOM%20killer%20-%20%D0%B2%D1%8B%D0%B6%D0%B8%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5.md)
    

---

### Что такое iowait и почему он может появляться?

- **Ответ**
    
    iowait это показатель, показывающий процентное соотношение времени процессора, которое он потратил на ожидание ввода-вывода.
    
    Высокий показатель может сказать о том, что система ограничена возможностями дисковой памяти. Выполняется много операций ввода-вывода. Это замедляет систему.
    Конкретно это обычно означает что блочные устройства работают медленно или они переполнены.
    
    Замеряется в количестве потоков, которые ждут работы.
    

    
---
### Что такое RAID? Какие основные типы RAID существуют, чем они отличаются?

- Ответ
    
    **RAID** (Redundant Array of Independent Disks/Избыточный массив независимых дисков) - это технология, 
    которая позволяет объеденить несколько независимых физических дисков в одну сущность.

    В работе с дисками есть две проблемы
    
    - Низкая скорость чтения\записи
    - Выход дисков из строя и потеря данных
    
    И это всё решается с помощью технологии RAID.
    
    Существуют следующие уровни спецификации RAID: 1,2,3,4,5,6,0. Кроме того, существуют комбинации: 01,10,50,05,60,06.  Существуют аппаратные и программные RAID-массивы.
    
    - Программные массивы создаются уже после установки Операционной Системы средствами программных продуктов и утилит, что и является главным недостатком таких дисковых массивов.
    - Аппаратные RAID’ы создают дисковый массив до установки Операционной системы и от неё не зависят.
    
    **RAID 0** - чередование
    
    **RAID 1** - зеркалирование
    
    **RAID 5** - чередование с четностью
    
    **RAID 6** - чередование с двойной четностью
    
    **RAID 10** - совмещение зеркалирования и чередования
    
    **Уровень RAID 0 - Чередование**
    
    В системе **RAID 0** данные разделяются на блоки, которые записываются на все диски в массиве. При одновременном использовании нескольких дисков (как минимум 2) это обеспечивает превосходную производительность ввода-вывода. Достигается это за счёт того что данные передаются контроллерам дисков по быстрой шине одновременно, и диски записывают данные на свои блины или чипы одновременно. Таким образом, эффективная скорость записи может вырасти кратно до числа дисков. Эту производительность можно повысить, используя несколько контроллеров, в идеале один контроллер на диск.
    
    ![raid-0-img](https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled%203.png)
    
    **Преимущества**
    
    - RAID 0 обеспечивает высокую производительность как в операциях чтения, так и записи. Нет никаких накладных расходов, вызванных контролем четности.
    - Используется весь объем памяти, накладных расходов нет.
    - Технология проста в реализации.
    
    **Недостатки**
    
    - RAID 0 не отказоустойчив.
    - В случае сбоя одного диска все данные в массиве RAID 0 будут потеряны.
    - Он не должен использоваться для критически важных систем.
    
    **Лучшее применение:**
    
    RAID 0 идеально подходит для некритического хранения данных, которые должны считываться/записываться с высокой скоростью, например, на ретушь изображений или на станции видеомонтажа.
    
    Если вы хотите использовать RAID 0 исключительно для объединения емкости хранилищ в одном томе, рассмотрите возможность подключения одного диска в путь к папке другого диска. Это поддерживается в Linux, OS X, а также Windows и имеет то преимущество, что сбой одного диска не влияет на данные второго диска.
    
    **Уровень RAID 1 - Зеркальное отображение**
    
    Данные хранятся дважды, записывая их как на основной диск (или набор дисков), так и на зеркальный диск (или набор дисков). В случае сбоя диска контроллер использует основной диск или зеркальный диск для восстановления данных и продолжает работу. Вам нужно как минимум 2 диска для массива RAID 1.
    
    ![raid-1-img](https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled%204.png)
    
    **Преимущества**
    
    - RAID 1 предлагает отличную скорость чтения и скорость записи, сопоставимую с одиночным диском.
    - В случае сбоя диска данные не нужно перестраивать, их просто нужно скопировать на новый диск.
    - RAID 1 - очень простая технология.
    
    **Недостатки**
    
    - Основным недостатком является то, что эффективная емкость хранилища составляет только половину от общей емкости диска, поскольку все данные записываются дважды.
    - Программные решения RAID 1 не всегда допускают горячую замену неисправного диска. Это означает, что неисправный диск можно заменить только после выключения компьютера, к которому он подключен.
    - Для серверов, которые используются одновременно многими людьми, это может быть неприемлемо. Такие системы обычно используют аппаратные контроллеры, которые поддерживают горячую замену.
    
    **Идеальное использование**
    
    RAID-1 идеально подходит для критически важных хранилищ, например, для учетных систем. Он также подходит для небольших серверов, в которых будут использоваться только два диска с данными.
    
    **RAID уровень 5**
    
    RAID 5 является наиболее распространенным безопасным уровнем RAID.  Требуется как минимум 3 диска, но может работать до 16. Блоки данных распределяются по дискам, и на одном диске записывается контрольная сумма четности всех данных блока.  Данные о четности не записываются на фиксированный диск, они распространяются на все диски, как показано на рисунке ниже.  Используя данные контроля четности, компьютер может пересчитать данные одного из других блоков данных, если эти данные больше не будут доступны.  Это означает, что массив RAID 5 может противостоять отказу одного диска без потери данных или доступа к ним.  Хотя RAID 5 может быть реализован программно, рекомендуется аппаратный контроллер.  Часто дополнительная кеш-память используется на этих контроллерах для улучшения производительности записи.
    
    ![raid-5-img](https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled%205.png)
    
    **Преимущества**
    
    - Транзакции чтения данных очень быстрые, в то время как транзакции записи данных несколько медленнее (из-за четности, которая должна быть рассчитана).
    - В случае сбоя диска у вас по-прежнему есть доступ ко всем данным, даже если неисправный диск заменяется, а контроллер хранилища восстанавливает данные на новом диске.
    
    **Недостатки**
    
    - Отказы дисков влияют на пропускную способность, хотя это все еще допустимо.
    - Это сложная технология. Если один из дисков в массиве, использующий диски 4 ТБ, выходит из строя и заменяется, восстановление данных (время восстановления) может занять день или более, в зависимости от нагрузки на массив и скорости контроллера. Если другой диск выйдет из строя в течение этого времени, данные будут потеряны навсегда.
    - При этом нагрузка на каждый из дисков возрастает, поэтому вероятность выхода из строя выше чем у любых других схем, а при выходе из строя одного диска алгоритм восстановления крайне активно работает со всеми дисками, что потенциально может привести к лавинообразному выходу из строя последующих дисков.
    
    **Идеальное использование**
    
    RAID 5 — это хорошая универсальная система, которая сочетает в себе эффективное хранилище с превосходной безопасностью и достойной производительностью. Он идеально подходит для файловых серверов и серверов приложений с ограниченным количеством дисков с данными.
    
    **Уровень RAID 6 - Чередование с двойной четностью**
    
    RAID 6 похож на RAID 5, но данные о четности записываются на два диска. Это означает, что для него требуется как минимум 4 диска и он может выдержать 2 диска, умирающих одновременно. Вероятность поломки двух дисков в один и тот же момент, конечно, очень мала. Тем не менее, если диск в системах RAID 5 умирает и заменяется новым, для восстановления замененного диска требуются часы или даже больше дня. Если в это время умирает другой диск, вы все равно теряете все свои данные. При использовании RAID 6 массив RAID переживет даже этот второй сбой.
    
    ![raid-6-img](https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled%206.png)
    
    **Преимущества**
    
    - Как и в RAID 5, операции чтения данных выполняются очень быстро.
    - Если два диска выйдут из строя, у вас все равно будет доступ ко всем данным, даже если вышедшие из строя диски заменяются. Таким образом, RAID 6 более безопасен, чем RAID 5.
    
    **Недостатки**
    
    - Операции записи данных выполняются медленнее RAID 5 из-за дополнительных данных о четности, которые необходимо рассчитать. Производительность записи теоретичски может быть на 20% ниже.
    - Отказы дисков влияют на пропускную способность, хотя это все еще допустимо.
    - Это сложная технология. Восстановление массива, в котором вышел из строя один диск, может занять много времени.
    
    **Идеальное использование**
    
    RAID 6 — это хорошая универсальная система, которая сочетает в себе эффективное хранилище с превосходной безопасностью и достойной производительностью. Это предпочтительнее, чем RAID 5 на файловых серверах и серверах приложений, которые используют много больших дисков для хранения данных.
    
    **RAID уровень 10 - объединение RAID 1 и RAID 0**
    
    Можно объединить преимущества (и недостатки) RAID 0 и RAID 1 в одной системе. Это вложенная или гибридная конфигурация RAID. Он обеспечивает безопасность путем зеркального отображения всех данных на вторичных дисках, в то же время используя распределение по каждому набору дисков для ускорения передачи данных.
    
    ![raid-10-img](https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled%207.png)
    
    **Преимущества**
    
    Если что-то идет не так с одним из дисков в конфигурации RAID 10, время восстановления очень быстрое, поскольку все, что нужно, - это скопировать все данные с выжившего зеркала на новый диск. Это может занять всего 30 минут для дисков емкостью 1 ТБ.
    
    **Недостатки**
    
    Половина емкости хранения уходит на зеркалирование, поэтому по сравнению с большими массивами RAID 5 или RAID 6 это дорогой способ обеспечения избыточности.
    
    **Как насчет уровней RAID 2, 3, 4 и 7?**
    
    Эти уровни существуют, но они не являются общими (RAID 3 по сути похож на RAID 5, но данные четности всегда записываются на один и тот же диск). В этой статье описывается лишь общая классификация RAID-систем, и отображает общие сведения о технологии объединения накопителей.
    
    **RAID не заменит резервную копию!**
    
    Все уровни RAID, кроме RAID 0, обеспечивают защиту от сбоя одного диска. Система RAID 6 продолжит работу, даже при выходе из строя одновременно 2 дисков. Для полной безопасности вам все равно необходимо выполнить резервное копирование данных из системы RAID.
    
    - Эта резервная копия пригодится, если все диски выйдут из строя одновременно из-за скачка мощности.
    - Это защита от кражи системы хранения.
    - Резервные копии могут храниться вне серверной комнаты или ЦОД, в другом месте. Это может пригодиться в случае чрезвычайного происшествия, масштабного системного сбоя, пожара и т.д.
    - Наиболее важной причиной резервного копирования данных нескольких поколений является ошибка пользователя. Если кто-то случайно удаляет некоторые важные данные, и это остается незамеченным в течение нескольких часов, дней или недель, хороший набор резервных копий гарантирует, что вы все равно сможете сохранить эти файлы.

---
### Какие средства для работы с программными RAID массивами существуют в linux?

- Ответ
    
    `mdadm`
    
    [https://www.dmosk.ru/miniinstruktions.php?mini=mdadm](https://www.dmosk.ru/miniinstruktions.php?mini=mdadm)
    

---

### Что такое LVM? Для решения каких задач он предназначен?

- Ответ
    
    менеджер, позволяющий управлять логическими томами в системах Linux. Сами логические тома можно собрать из нескольких дисков или разделов дисков. LVM расшифровывается как Logical Volume Manager или по-русски — менеджер логических томов.
    
    LVM или Logical Volume Manager - это еще один программный уровень абстракции над физическими разделами жесткого диска, который позволяет создавать логические тома для хранения данных без непосредственной переразметки жесткого диска на одном или нескольких жестких дисках. LVM увеличивает удобство работы с жестким диском, аппаратные особенности работы скрываются программным обеспечением, поэтому вы можете изменять размеры дисков, перемещать их на лету, без остановки приложений или размонтирования файловых систем. Это очень удобно на серверах, вы можете добавить еще один диск или расширить существующие lvm тома на лету.
    

---

## Docker контейнеры

**Что такое контейнеризация? Чем она отличается от виртуализации?**

- Ответ
    
    ![container-vs-vm-img](https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled%208.png)
    
    Если говорить о виртуальных машинах, там они работают через **Виртуализацию**
    
    И машины создаются с помощью гипервизора. И все аппаратные составляющие создаются через нее. И затем на нее накатываются операционные системы.
    Соответственно, ресурсы машины будут уходить на поддержание работы запущенной операционной системы.
    
    При контейнеризации аппаратные ресурсы выделяются с помощью ядра операционной системы, и изолируются пространством имен. Следовательно, они потребляют меньше ресурсов, и быстрее пересоздаются.
    
    Плюсы:
    
    - Меньше ресурсов потребляется
    - Быстрый запуск
    

---

### Что такое docker и какие инструменты linux лежат в основе? Для чего он используется?

- Ответ
    
    Docker базируется на технологиях **namespaces**, **cgroups**, **capabilities**, **overlay**
    **namespaces** - обеспечивает изоляцию. Используется для изоляции. Например, можно айдишники процессов разместить в разных контейнерах.
    **cgroup** - штука, которая позволяет управлять группой процессов, и управлять их ресурсами.
    **capabilites** - штука, которая позволяет дать некоторые рут привелегии процессам или исполняемым файлам. Например, изменить UID процесса на 0, или дать возможность монтировать файловые системы.
    **overlay (overlayFS, overlay2-драйвер)** - файловая система, которая умеет работать "слоями". Не сохранять каждый раз новые файлы, а наслаивать один слой на другой, тем самым экономя место на диске и время создания контейнера. 
    
    А вот докер - это уже штука, которая всеми этими технологиями рулит. Да ещё и удобным для нас образом.
    
    

    Компоненты докера:  
    1. Docker Daemon — то самое Container Engine; запускает контейнеры.
    2. Docker CII — утилита по управлению Docker.
    3. Dockerfile — инструкция по тому, как собирать образ.
    4. Image — образ, из которого раскатывается контейнер.
    5. Container.
    6. Docker registry — хранилище образов.
    
    ![docker-basic-img](https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled%209.png)
    
    На Docker_host работает Docker daemon, запускает контейнеры. Есть Client, который передаёт команды: собери образ, скачай образ, запусти контейнер. Docker daemon ходит в registry и выполняет их. Docker-клиент может обращаться и локально (к юникс-сокету), и по TCP с удалённого хоста.
    
    
    Docker daemon (демон)
    
    — это серверная часть, она работает на хост-машине: скачивает образы и запускает из них контейнеры, создаёт сеть между контейнерами, собирает логи. Когда мы говорим «создай образ», этим тоже занимается демон.
    
    Docker CLI
    
    — клиентская часть Docker, консольная утилита для работы с демоном. Повторю, она может работать не только локально, но и по сети.
    

---
### Что такое контейнеры, образы? В чём заключаются концепции их использования?

- Ответ
    
    **Образ** - шаблон приложения, который содержит слои файловой системы в режиме "только-чтение".
    
    **Контейнер** - запущенный образ приложения, который кроме нижних слоев в режиме "только чтение" содержит верхний слой в режиме "чтение-запись".
    
    Контейнер - это уже развернутое и запущенное приложение. Однажды запущенный контейнер сохранён в библиотеке, его можно останавливать, менять настройки, перезапускать, но до удаления контейнера это некоторая постоянная сущность со своим id. Продолжая аналогию с установкой ПО, контейнер можно сравнить с уже установленной и работающей программой на ПК.
    
    Образ - Это неизменяемый образ, из которого разворачивается контейнер. Его можно рассматривать как набор файлов, необходимых для запуска и работы приложения на другом хосте. Можно привести аналогию из мира установки ПО: образ — это компакт-диск, с которого устанавливается программа.
    

---
### В каком виде хранятся образы? Для чего используются слои? Что представляет собой overlayfs?

- Ответ
    
    **Образы(images)** - это логическая группировка слоев плюс метаданные о том, что делать при создании контейнера и как собирать слои. Часть этих метаданных заключается в том, что каждый слой знает ID своего родителя.
    
    Итак, что входит в слой? Файлы (и каталоги), которые вы добавили в родительский файл. Существуют также специальные файлы ("whiteout"), которые указывают на то, что что-то было удалено из родительского файла.
    
    Docker-image — шаблон только для чтения (read-only) с набором некоторых инструкций, предназначенных для создания контейнера. Он состоит из слоев, которые Docker комбинирует в один образ при помощи вспомогательной файловой системы UnionFS. Так решается проблема нерационального использования дисковой памяти. Параметры образа определяются в Docker-file.
    

---

### Что такое docker commit

- Ответ
  Это утилита, с помощью которой можно сощздать новый образ на основе контейнера либо перезаписать текущий образ

  Может быть полезно когда ты что ты изменил какой то файл в docker контейнере, и тебе нужно сохранить этот новый рабочий обновленный образ.


---
### Каким образом в docker реализована изоляция контейнеров друг от друга? Какие средства linux для этого используются?(namespace)

- Ответ
    
    Докер используется namespaces. Для создания изолированного рабочего пространства, которое называется контейнером. 
    При запуске контейнера докер создает набор неймспейсов для этого контейнера.

    Эти неймспейсы обеспечивают уровень изоляции. Каждый аспект контейнера выполняется в отдельном контейнере и его доступ ограничен неймспейсом.

    В частности в Docker Engine использует следующее:
    - Пространство имен pid: Изоляция процессов (PID: идентификатор процесса).
    - Пространство имен net: Управление сетевыми интерфейсами (NET: Networking).
    - Пространство имен ipc: Управление доступом к ресурсам IPC (IPC: InterProcess Communication).
    - Пространство имен mnt: Управление точками монтирования файловой системы (MNT: Mount).
    - Пространство имен uts: Изолирование идентификаторов ядра и версий. (UTS: Unix Timesharing System).
        

---
### Почему в контейнере можно увидеть только процессы, запущенные в самом контейнере?

- Ответ

    Это связано с тем, что Docker использует пространство имен PID (Process ID) для обеспечения изоляции процессов в контейнерах. 
    Когда создается новый контейнер, Docker создает новое пространство имен PID для этого контейнера и запускает процесс в этом пространстве имен. 

    В этом изолированном пространстве имен PID относится только к процессам, запущенным в том же контейнере.  
    Это означает, что процесс в контейнере **может видеть только другие процессы в том же контейнере и не имеет возможности видеть процессы, запущенные в других контейнерах или на хост-системе**. 
    Это ключевой аспект изоляции и безопасности, обеспечиваемой контейнерами Docker.
    
---
### Какие типы сетей есть в докере

- Ответ  
  **bridge** - Это стандартная сеть по умолчанию, которая создает виртуальный мост (bridge) для обмена данными между контейнерами. Каждый контейнер получает собственный IP-адрес из диапазона сети Docker.

  **host** - использует сетевой стек хоста, что означает, что контейнеры не изолированы на уровне сети от хоста. То есть, контейнер не изолирован по портам и делает запросы напрямую через сеть хоста.

  **none** - контейнер не имеет доступа к сети.

  **overlays** - тип сетей которые пересекают несколько узлов. Полезно когда у тебя docker контейнеры запушенны на разных хостах, но они должны общаться между собой. Для реализации этой сети Docker использует технологии, такие как **VXLAN** (Virtual Extensible LAN).

---
### Что происходит когда пишешь ENTRYPOINT?

- Ответ
    
    Точка входа в приложение.

    Это инструкция в докерфайле, которая всегда будет выполняться при запуске контейнера. 
    Она часто используется для определения основной команды для запуска контейнера. 
    Например для запуска веб-сервера или какой-либо иной службы. 

    Что происходит пошагово:    
    Инструкция ENTRYPOINT в Dockerfile задает команду, которая всегда будет выполняться при запуске контейнера. Она часто используется для задания основной команды для запуска контейнера, например, для запуска веб-сервера, базы данных или службы.
    Вот что происходит шаг за шагом:  

    1. В процессе сборки образа Docker читает Dockerfile строка за строкой, сверху вниз. Когда Docker встречает инструкцию ENTRYPOINT, он записывает команду и ее аргументы.  

    2. После сборки образа, при запуске контейнера из этого образа Docker выполняет команду, указанную в инструкции ENTRYPOINT. 

    3. Если команда Docker run также включает в себя команду, то она передается в качестве аргумента команде ENTRYPOINT.  

    Например, если у вас есть Dockerfile со следующим ENTRYPOINT:

    ```
    ENTRYPOINT ["/app/start.sh"]
    ```

    И запускается контейнер из этого образа с помощью команды:

    ```
    docker run -it my_image echo "Hello, World!"
    ```

    Докер выполнит команду ENTRYPOINT с командой run в качестве аргумента:

    ```
    /app/start.sh echo "Hello, World!"
    ```

    Обратите внимание, что команду ENTRYPOINT можно отменить при запуске контейнера, используя флаг `--entrypoint` в команде `docker run`.
    В этом основной смысл, что можно переопределить аргумент, или вообще его отменить.

### В чем отличие CMD и ENTRYPOINT

- Ответ
    
    Эти инструкции Dockerfile задают команду, исполняемую при запуске контейнера. При их использовании есть несколько правил, например:
    
    - Должна быть минимум одна из них, CMD или ENTRYPOINT, в Dockerfile.
    - Если контейнер используется как исполняемый файл — ENTRYPOINT должна быть определена.
    - Если контейнер запускается с другими аргументами — CMD будет переопределена.
    
    Инструкция RUN позволяет вам установить ваше приложение и необходимые для него пакеты. Он выполняет любые команды поверх текущего изображения и создает новый слой, фиксируя результаты. Часто в Dockerfile вы найдете несколько инструкций RUN.
    
    Хорошей иллюстрацией инструкции RUN может быть установка нескольких пакетов систем контроля версий:
    
    ```
    RUN apt-get update && apt-get install -y \
      bzr \
      cvs \
      git \
      mercurial \
      subversion
    ```
    
    Обратите внимание, что `apt-get update`и `apt-get install`выполняются в одной инструкции RUN. Это делается для того, чтобы убедиться, что будут установлены самые последние пакеты. Если бы `apt-get install`это была отдельная инструкция RUN, то она бы повторно использовала слой, добавленный `apt-get update`, который мог быть создан давным-давно.
    
    Инструкция CMD позволяет вам установить команду по *умолчанию* , которая будет выполняться только тогда, когда вы запускаете контейнер без указания команды. Если контейнер Docker запускается с командой, команда по умолчанию будет игнорироваться. Если Dockerfile содержит более одной инструкции CMD, все инструкции CMD, кроме последней, игнорируются.
    
    CMD имеет три формы:
    
    - `CMD ["executable","param1","param2"]`
        
        (исполнительная форма, предпочтительнее)
        
    - `CMD ["param1","param2"]`*exec*
        
        (устанавливает дополнительные параметры по умолчанию для ENTRYPOINT в форме
        
    - `CMD command param1 param2`
        
        (форма оболочки)
        
        `docker run -it <image> /bin/bash` - тут при наличии CMD он будет проигнорирован, и будет запущен баш
        
        Инструкция ENTRYPOINT позволяет настроить контейнер, который будет работать как исполняемый файл. Он похож на CMD, потому что также позволяет указать команду с параметрами. Разница заключается в том, что команда ENTRYPOINT и параметры не игнорируются, когда контейнер Docker запускается с параметрами командной строки. (Есть способ игнорировать ENTTRYPOINT, но вряд ли вы это сделаете.)
        
        Докерфайл
        
        ```
        ENTRYPOINT ["/bin/echo", "Hello"]
        CMD ["world"]
        ```
        
        когда контейнер запускается, как `docker run -it <image>`будет производиться вывод
        
        ```
        Hello world
        
        ```
        
        но когда контейнер запускается, `docker run -it <image> John`это приведет к
        
        ```
        Hello John
        ```
        
- Краткий ответ
    
    cmd подставится после entrypoint при запуске. Тем самым можно запускать контейнер с нужными параметрами.
    
    То есть в entrypoint можно передать бинарь, а в cmd передать параметры.
    
    CMD может перетереться просто.
    
---

### Как уменьшить размер образа докера? У нас много COPY, RUN

- Ответ
    1. Использовать специальные облегченные базовые версии докер-образов.
    2. Уменьшать размер слоев, запуская RUN нечасто, объединив команды в одну
    3. Не устанавливать рекомендованные пакеты. И удалять содержимое `/var/lib/apt/lists/*`
    4. Docker-multistage-build. Тут указываем несколько `FROM`. И можно копировать результат одного `FROM-а` в другой
        - Пример
            
            ```docker
            # 1 =====================================
            # специальный образ, который содержит все необходимые 
            # для сборки библиотеки и приложения
            # размер образа ~730mb
            FROM diproart/ruby:2.6.4-alpine3.10 AS builder
            
            # полный набор пакетов
            ENV COMMON_PACKAGES \
            	tzdata \
                ...
                
            ENV ..
            
            RUN set -xe \
                && apk update \
                && apk upgrade \
                && apk add --no-cache --update ${COMMON_PACKAGES} \
                && rm -rf /var/cache/apk/* /tmp/* /var/tmp/*
            
            # additional clean
            #RUN rm -rf /usr/local/bundle/cache/*gem     
            
            RUN mkdir -p /usr/src/app
            WORKDIR /usr/src/app
            COPY . .
            RUN 
            
            # 2 =====================================
            # чистый образ, в который добавим только самое необходимое
            # размер образа ~51mb
            FROM ruby:2.6.4-alpine3.10
            
            # только необходимые для работы 
            # в production пакеты
            ENV PRODUCTION_PACKAGES \
            	tzdata \
                ...
            
            ENV ...
            
            RUN set -xe \
                && apk update \
                && apk upgrade \
                && apk add --no-cache --update ${PRODUCTION_PACKAGES} \
                && rm -rf /var/cache/apk/* /tmp/* /var/tmp/*
            
            RUN mkdir -p /usr/src/app
            WORKDIR /usr/src/app
            
            WORKDIR /usr/src/app
            
            # копируем скомпилированное приложение
            # и пакеты в напрямую в образ из предыдущего шага
            COPY --from=builder /usr/src/app .
            COPY --from=builder /usr/local/bundle/ /usr/local/bundle/
               
            EXPOSE 3000
            ENTRYPOINT [ "bundle", "exec" ]
            CMD [ "rails", "s", "-b", "0.0.0.0" ]
            ```
            
---

### Разработчики собрали образ, и запустили докер контейнер. При запуске выдает ошибку /bin/bash not found. Как диагностировать проблему?

- Ответ

  Попробовать запустить с sh, bash переопределив энтрипоинт
  ```
  docker run  --entrypoint="/bin/sh"  
  ```
  

---
### Какие команды порождают слои?

- Ответ
    
    `RUN` порождает слои
    
---

### Что такое squash сквош?

- Ответ
    
    Это штука, позволяющая все слои спушить в один. В качестве побочного эффекта - размер образа уменьшается. 
    
    Но он ломает кэширование, поскольку у нас всё в одном слое. 
    
    С одной стороны инструмент мощный. Но нужно обращаться осторожно. 
    Лучше для базового образа использовать. Заранее набросал, и вот у тебя образ.



---
### Можно ли ограничить использование ресурсов (cpu, ram, io, network) для docker контейнера? Как это реализовано? (cgroup)**

- Ответ
    
    Можно. И делается через cgroup. В модуле ядра.
    
    А можно посмотреть в докере как ключи ставить
    
    [https://docs.docker.com/config/containers/resource_constraints/](https://docs.docker.com/config/containers/resource_constraints/)
    

---
### Для решения каких задач применяется docker-compose?

- Ответ
    
    Docker Compose — это инструментальное средство, входящее в состав Docker. Оно предназначено для решения задач, связанных с развёртыванием проектов.
    Вы передаёте файл с инструкциями для docker-compose, настроечными файлами, и докер на месте собирает из этого нужную вам комбинацию контейнеров, подтягивает образы нужных версий, пробрасывает в них волюмы с данными, поднимает между ними локальные сети и настраивает порты обмена.

---
### В чем разница между `docker stop` и `docker pause`?

- Ответ
    
    В том, что они посылают разные сигналы 
    
    docker pause - SIGSTOP(19), что приостанавливает процессы в контейнере
    
    docker stop - SIGTERM(15) и SIGKILL(9) использует к главному процессу контейнера
    

### Что такое слои в докере?

- Ответ
    
    По сути, слой или *слой образа*
     - это изменение образа или **промежуточного образа**. Каждая команда, указанная (  
    `FROM`,  
    `RUN`,  
    `COPY`  
    и т.д.) в вашем Dockerfile вызывает предыдущий образ изменения, создавая тем самым новый слой. Вы можете думать об этом как о внесении изменений при использовании git: вы добавляете изменение файла, затем еще одно, затем добавляя ещё одно, и слои накладываются один за другим.

    Так же любые изменения, которые происходят в docker контейнере, автоматически записываются в новый слой.
    

### В чем разница между ADD и COPY

- Ответ  
    В Dockerfile, инструкции `ADD` и `COPY` обе используются для копирования файлов и директорий из локальной файловой системы в образ контейнера, но между ними есть несколько важных различий:  
    * **COPY** поддерживает **только** базовое копирование локальных файлов в контейнер  
    * **ADD** имеет дополнительный функционал, к примеру, может извлекать архивы (напр, .tar, .tar.gz, .zip и другие форматы) и загружать файлы по URL. Но если, например, копировать через него архив, то он распакуется как каталог. Это уменьшает размер образа  

  В большинстве случаев предпочтительнее использовать COPY, так как это более предсказуемо и ясно, а ADD стоит использовать только тогда, когда вам действительно нужны её дополнительные возможности, такие как извлечение архивов или загрузка файлов по URL.

  ---

  ### В чем отличие ARG от ENV?

- Ответ
    
    **ENV** позволяет создавать переменные окружения, которые будут работать во время работы контейнера.
    
    **ARG** позволяет закинуть переменные, которые будут доступны во время сборки. Но они недоступны в контейнере. Однако через `ARG` можно задавать значения переменных по умолчанию для `ENV`

---
### От кого по умолчанию запускается контейнер? Почему это плохо?

- Ответ
    
    Процесс внутри пользователя запускается от root. id = 0.
    
    Лучше вот так делать
    
    ```docker
    FROM alpine
    RUN groupadd -r myuser && useradd -r -g myuser
    <Здесь еще можно выполнять команды от root-пользователя, например, ставить пакеты>
    USER myuser
    ```
    
    Можно таким образом нарушить изоляцию и получить рутовый доступ.
    
    Ну и не все запускают от рута в итоге
    
---
### Возможен ли самостоятельный перезапуск контейнера?

- Ответ
    
    Да, можно вот так указать:
    
    `docker run --restart=always`
    
---

### Какие есть best practices для написания Dockerfile?

- Ответ
    1. Запускать только один процесс на контейнер.
    2. Стараться объединять несколько команд **RUN** в одну для уменьшения количества слоёв образа.
    3. Частоизменяемые слои образа необходимо располагать ниже по уровню,
    чтобы ускорить процесс сборки, т.к. при изменении верхнего слоя, все
    нижеследующие слои будут пересобираться.
    4. Указывать явные версии образов в инструкции **FROM**, чтобы избежать случая, когда выйдет новая версия образа с тегом **latest**.
    5. При установке пакетов указывать версии пакетов.
    6. Очищать кеш пакетного менеджера и удалять ненужные файлы после выполненной инструкции.
    7. Использовать **multistage build** для сборки артефакта в одном контейнере и размещении его в другом.

---

## Сети сеть

### Чем отличается TCP от UDP?

- Ответ
    
    **TCP** – транспортный протокол передачи данных в сетях TCP/IP, предварительно устанавливающий соединение с сетью. Ориентирован на соединение, используется для передачи данных (электронная почта, файлы, сообщения). При определении потери пакетов будет выполнен перезапрос потерянных пакетов.
    
    **UDP** – транспортный протокол, передающий сообщения-датаграммы без необходимости установки соединения в IP-сети. Не ориентирован на установление соединения, используется в потоковой передаче данных (IPTV, VoIP). При потере пакетов перезапроса потерянных пакетов не происходит.
    
    Нельзя сказать, что TCP лучше UDP, т.к. данные транспортные протоколы используются для различных типов передачи трафика.
    
- Ответ чтоб меньше доебывали
    
    tcp перед передачей сигнала устанавливает связь между устройствами. И он требует хендшейк.
    udp сразу отправляет, хендшейк не устанавливает. Возможна частичная потеря и несоблюдение порядка данных.
    Но что делать, если доставка не гарантирована в таком случае? Просто отправляются по два пакета. Если один потерялся - дойдет второй.

---

### Как TCP устанавливает соединение?

- Ответ
    
    ![tcp-con-img](https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled%2010.png)
    
    1. Клиент, который намеревается установить соединение, посылает серверу сегмент с номером последовательности и флагом `SYN`. Он является пакетом синхронизации. Устанавливается только в первом пакете хоста и сервера. Позволяет установить сеанс, делая возможным обеим сторонам согласовать порядковый номер для начала связи.
       Дальнейший алгоритм: Сервер получает сегмент, запоминает номер последовательности и пытается создать сокет (буферы и управляющие структуры памяти) для обслуживания нового клиента;    
       В случае успеха сервер посылает клиенту сегмент с номером последовательности и флагами SYN и ACK, и переходит в состояние SYN-RECEIVED;  
       В случае неудачи сервер посылает клиенту сегмент с флагом RST.
    2. Если клиент получает сегмент с флагом SYN, то он запоминает номер последовательности и посылает сегмент с флагом ACK. Дальнейший алгоритм: Если он одновременно получает и флаг ACK (что обычно и происходит), то он переходит в состояние ESTABLISHED; Если клиент получает сегмент с флагом RST, то он прекращает попытки соединиться; Если клиент не получает ответа в течение 10 секунд, то он повторяет процесс соединения заново.  
    3. Если сервер в состоянии SYN-RECEIVED получает сегмент с флагом ACK, то он переходит в состояние ESTABLISHED. В противном случае после тайм-аута он закрывает сокет и переходит в состояние CLOSED. Процесс называется «трёхэтапным рукопожатием» (англ. three way handshake), так как несмотря на то что возможен процесс установления соединения с использованием четырёх сегментов (SYN в сторону сервера, ACK в сторону клиента, SYN в сторону клиента, ACK в сторону сервера), на практике для экономии времени используется три сегмента.

---

### Как TCP поддерживает соединение?

- Ответ
    
    Многие реализации TCP способны посылать сообщение о *поддержании соединения*
     (keep-alive), тестирующее неактивные соединения.
    
    Такие сообщения периодически отправляются партнеру для проверки его существования в сети. В ответ должны поступать сообщения ACK. Использование сообщений о поддержании соединения не является обязательным. Если в системе имеется такая возможность, приложение может отменить ее собственными средствами. Предполагаемый период *по умолчанию*
     для тайм-аута поддержания соединения составляет целых два часа!

--- 

## Что происходит когда в браузере вводишь yandex.ru? Описать процесс

- Ответы
    
    Любой URL содержит следующую структуру `<протокол>/<хост>/путь`, например `https://yandex.ru/pogoda/samara`. Также URL может содержать данные для отображения страницы.
    
    1. При вводе URL браузер смотрит на протокол запроса. Если протокол в URL не указан, то браузер смотрит на список HSTS (HTTP Strict Transport Security - механизм, принудительно активирующий защищенное соединение через протокол HTTPS), если хост есть в данном списке, то браузер отправит запрос по протоколу HTTPS, если нет, то по HTTP.
    2. Для того, чтобы установить соединение с сервером, необходим его IP адрес. Так как мы используем домен, то необходимо установить соответствие домена и IP адреса сервера, где размещается ресурс. При запросе мы обращаемся к DNS. Cначала проверяется кеш DNS. Приоритет опроса DNS кеша следующий:
    - Кеш браузера,
    - Проверяется hosts файл ,
    - Кеш ОС,
    - Кеш роутера,
    - Кеш интернет-провайдера Если данных о данном запрашиваемом хосте в кеше нет, то:
    - DNS интернет провайдера отправляет запрос к корневому серверу DNS (.),
    - Если корневой сервер не знает запрашиваемого домена, то он отправляет запрос серверу ответственному за зону (.ru), в которому привязан домен,
    - Если DNS сервер зоны не знает запрашиваемого домена, то запрос отправляется к NS серверу домена. IP адрес хоста, при его наличии у DNS сервера, возвращается обратно по цепочке
    
    3. После того, как IP адрес хоста получили, необходимо сформировать на прикладном уровне запрос к серверу. К запросу добавляются следующие заголовки:
    - Прикладной уровень: протокол запроса (HTTP/S, FTP и т.д),
    - Транспортный (TCP/UDP): порт, по которому обращаемся к серверу.
    - Сетевой уровень: IP адрес пакета
    - Канальный уровень: определяет есть ли такой адрес в сети. Если нет, то пакет передаётся шлюзу. Устройство шлюза проверяет свою таблицу маршрутизации и направляет пакет в нужном направлении.
    - 
    4. Далее выполняется следующий алгоритм действий установления соединения:
    - После того, как запрос достиг сервера, клиент отправляет клиенту запрос (client hello) и свою версию протокола TLS на защищенное соединение.
    - Сервер отвечает клиенту (server hello) с информацией о выбранной версии TLS, методом шифрования, методом компресии и публичный сертификат сервера, подписанный центром сертификации. Сертификат содержит публичный ключ, который будет использован клиентом для шифрования данных.
    - Клиент подтверждает сертификат сервера с помощью своего списка центров сертификации. Если сертификат подписан центром из списка, то серверу можно доверять.
    - Клиент шифрует данные публичным ключом и отправляет серверу зашифрованное сообщение.
    - Сервер расшифровывает сообщение с помощью своего приватного ключа и генерирует симметричный мастер-ключ и отправляет его клиенту.
    - Клиент отправляет серверу сообщение о финише, шифруя хэш передачи с помощью симметричного ключа.
    - Сервер генерирует собственный хеш, а затем расшифровывает полученный от клиента хэш, чтобы проверить совпадает ли хэш клиента с хэшом сервера. Если совпадение обнаружено, то сервер отправляет клиенту сообщение о финише.
    
    После этого защищенное соединение с сервером установлено.
    
    5. Далее необходимо сформировать запрос серверу:
    - Клиент формирует запрос HTTP, в котором участвует метод (например GET), URL и версию протокола. Например `GET /pogoda/samara HTTP/2`.
    - Следующий заголовок клиента HOST, в котором указывается к какому хосту необходимо обратиться. Например `HOST: yandex.ru`. По заголовку HOST сервер может определить к какому сайту на сервере необходимо обратиться.
    - Запрос может также содержать и другие заголовки. Необходимо только, чтобы сервер смог понять эти заголовки.
    
    После этого всё, соединение установлено
    
---

### Как работает NAT, зачем он нужен?

- Ответ
    
    #### Частные и публичные IP-адреса. NAT (Network Address Translation)

    Изначально сети проектируются с использованием **частных IP-адресов**. Эти IP используются внутри площадки или организации для общения устройств в локальной сети. Однако, для того чтобы устройства могли взаимодействовать с внешними ресурсами за пределами локальной сети, их **частные IP-адреса** должны быть преобразованы в **публичные**.
    
    #### NAT (Network Address Translation)
    
    **NAT** — это технология, которая занимается переводом частных IP-адресов в общедоступные. **NAT** позволяет устройствам с частными адресами IPv4 обращаться к внешним ресурсам за пределами локальной сети. 
    
    Технология NAT полезна в контексте сохранения ограниченного количества общедоступных IPv4-адресов. Она позволяет многим устройствам в частной сети использовать один публичный IP-адрес для выхода в интернет.
    
 ---

### Почему DNS использует UDP?

- Ответ
    
    Пока устраиваешь TCP-сессию, ты можешь 3 раза отправить UDP пакетик туда и получить его обратно. И никакого оверхеда.
    
---
### Как работает traceroute?  
 
- Ответ  
  В первую очередь это тоже утилита, как и пинг. И основываться может либо на ICMP, либо на UDP, и даже на TCP.   
  Нужна для того, чтобы определить маршруты следования данных по сети.     
  В отличие от ping, который лишь сообщает о проблеме, помогает точнее определить где возникла проблема.    
  В целом это второй инструмент, который помогает сузить круг поиска возможных проблем при сетевой недоступности.

  **Как работает?**
  * На вход даётся конечный адрес назначения (destination, dst).   
  * Программа генерирует серию сообщений, начиная с **TTL** = 1.    
  * Каждый маршрутизатор на пути уменьшает **TTL** на 1.   
  * Когда **TTL** достигает 0, маршрутизатор отбрасывает пакет и отправляет ICMP "Time Exceeded" обратно.   
  * Traceroute фиксирует этот ответ и IP-адрес отправителя.    
  * Процесс повторяется с увеличением **TTL** на 1, пока не достигнет конечного адреса. Либо пока не кончатся переходы (самое большое число 255). То есть в данном случае TTL будет 2. Первый запрос попадет на наш первый маршрутизатор. TTL уменьшится на 1. И маршрутизатор отправит запрос на следующий маршрутизатор. После чего TTL будет 0 и пакет отбросится.  
  * Если используется UDP, на закрытый порт конечного хоста придёт ICMP "Port Unreachable".    

  Что позволяет найти, какие ошибки?   
  * Полный путь, который проходит пакет   
  * Увидеть имена, адреса маршрутов и\или иных устройств на пути следования пакетов  
  * Сетевые задержки, сколько времени нужно для отправки и получения данных всем устройствам  


  Минусы:  
  Это занимает много времени как правило  
  Тут может быть нюанс, что маршрутизаторы могут не давать ответа, не отвечать на UDP\TCP\ICMP-echo запросы.  
  И пробовать нужно будет разные варианты. И в целом это лишь один из инструментов диагностики.      

  https://youtu.be/HgYuBN0ZYu0

  https://predzimye.livejournal.com/16179.html  

---
### Как узнать мой внешний ip адрес?
- Ответ
  Проще всего это выяснить, сделав запрос на сервисы по типу 2ip.ru, и им подобных.
  `$ curl 2ip.ru`  
  Там будет сразу выведен адрес.
---

### Как работают сертификаты? Как подтверждается соединение? (https соединение)

- Ответ
    
    Процесс работает следующим образом:
    
    1. Браузер или сервер пытается подключиться к веб-сайту (веб-серверу), защищенному с помощью SSL.
    2. Браузер или сервер запрашивает идентификацию у веб-сервера.
    3. В ответ веб-сервер отправляет браузеру или серверу копию своего SSL-сертификата и публичный ключ.
    4. Браузер или сервер проверяет, является ли этот SSL-сертификат доверенным. У него уже зашиты сервера с помощью которых нужно производить проверку, с помощью центров сертификации. Если это так, он сообщает об этом веб-серверу. Генерирует сенасовый ключ, шифрует пебличным ключом и отправляет на сервер.
    5. Сеервер расшифровывает сообщение и сохраняет сеансовый ключ. Затем веб-сервер возвращает подтверждение с цифровой подписью и начинает сеанс, зашифрованный с использованием SSL.
    6. Зашифрованные данные используются совместно браузером или сервером и веб-сервером.
    
    Этот процесс иногда называют подтверждением SSL-соединения. Хотя по описанию этот процесс выглядит длительным, в реальности он занимает миллисекунды.
    
    ![ssl-img](https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled%2013.png)
    

---

### Какие стандартные коды ответов есть у веб-серверов?

- Ответ
    - 1XX — информационные коды. Они отвечают за процесс передачи данных. Это временные коды, они информируют о том, что запрос принят и обработка будет продолжаться.
    - 2XX — успешная обработка. Запрос был получен и успешно обработан сервером.
    - 3XX — перенаправление (редирект). Эти ответы сервера гласят, что нужно предпринять дальнейшие действия для выполнения запроса. Например, сделать запрос по другому адресу.
    - 4XX — ошибка пользователя. Это значит, что запрос не может быть выполнен по его вине.
    - 5XX — ошибка сервера. Эти коды возникают из-за ошибок на стороне сервера. В данном случае пользователь всё сделал правильно, но сервер не может выполнить запрос. Для кодов этого класса сервер обязательно показывает сообщение, что не может обработать запрос и по какой причине.

---
### Какие существуют основные типы запросов HTTP?

- Ответ
    
    Два наиболее часто используемых видов HTTP запросов это: GET и POST.
    
    **GET** - запрашивает данные с определенного ресурса (сайта). 
    
    **POST** - отправляет данные на сервер для последующей их обработки.
    
    **Особенности GET запроса:**
    
    - Может быть закэширован
    - Остается в истории браузера
    - Может быть закладкой в браузере
    - Не должен использоваться при работе с крайне важными данными
    - Имеет ограниченную длину
    - Должен применяться только для получения данных
    
    **Особенности POST запроса:**
    
    - Не кэшируется
    - Не может быть закладкой в браузере
    - Не остаётся в истории браузера
    - Нет ограничений по длине запроса
    
    **post_error**
    [Untitled](%D0%92%D0%BE%D0%BF%D1%80%D0%BE%D1%81%D1%8B%20%D0%B0%D0%B4%D0%BC%D0%B8%D0%BD%D0%B0%D0%BC%202%200%2060c73919d6564d1e880f209921e7b84d/Untitled%20Database%2026b6f5f23de74bf88002e57c48e41ea6.csv)
    

---
### Расскажи про модель TCP IP 

- Ответ

   4. Прикладной(хттп, ftp, SMTP, DNC и тд)
   3. Транспортный(передача данных, либо дейтаграмм в udp)
   2. Межсетевой(маршрутизаторы, роутеры и тд)
   1. Канальный уровень(подготовка пакета)

   ![TCP/IP-img](./imgs/TcpIp.png)


   Можно описать на примере работы протокола SSH

   1. **Канальный уровень**
      Здесь данные формируются во фреймы для передачи, а также ведется контроль доступа к среде передачи данных. 
   2. **Сетевой уровень**
      Этот слой отвечает за определение пути, по которому будет следовать пакет данных.
   3. **Транспортный уровень**
       Этот слой управляет передачей данных от одной системы к другой. SSH взаимодействует с этим слоем через протокол TCP.
   4. **Прикладной уровень**
       В первую очередь этот уровень предоставляет инструменты для взаимодействия пользовательских приложений с сетью. Все делается так, чтобы данные доходили в понятном пользователю или софту виде.
       SSH функционирует на этом слое, предоставляя защищенный канал для удаленной сессии или туннелирования других сетевых протоколов.


---
## Ansible

### Для чего нужен ad hoc в ansible?

- Ответ
    
    Это режим работы ансибл когда запрос к серверу выполняется напрямую из командной строки, без создания дополнительных файлов.
  
---
### Что такое роли в ansible, пример

- Ответ
    
    Роли имеют свою структуру каталогов, которая выглядит так:
    
    ```yaml
    rolename
     - files
     - handlers
     - meta
     - templates
     - tasks
     - vars
    ```
    
    Назначение директорий:
    
    - `files`: содержит файлы, которые будут скопированы на настраиваемые хосты; так же – может содержать скрипты, которые позже будут запускаться на хостах;
    - `handlers`: обработчики, которые будут использоваться при выполнении задач;
    - `meta`: описание зависимостей, т.е. – ролей, которые должны быть обработаны перед запуском настраиваемой роли и мета-данных, таких как автор, описание продукта и прочее;
    - `templates`: шаблоны файлов с переменными;
    - `tasks`: все задачи, которые ранее были описаны в *Playbook*е;
    - `vars`: переменные для шаблонов.
    
    Тут описывается установка nginx
    
    [https://rtfm.co.ua/ansible-roli-roles-primer/](https://rtfm.co.ua/ansible-roli-roles-primer/)

---  
### Что такое идемпотентность? Приведи пример таких операций, и противоположных им

- Ответ
    
    Идемпотентность это когда делаем одну и ту же операцию много раз, и при многократном ее повторении результат будет таким же, как в первый раз. Некоторые операции не являются идемпотентными сами по себе, и там потребуется дополнительная логика.
    
    Например, делаем запрос к странице, просто ее качаем - это идемпотентно. Потому что результат не изменится.
    
    Допустим делаем DELETE запрос. Он сам по себе тоже идемпотентен, ибо удаляет то, что мы хотели изначально удалить. Однако, сначала сервер ответил 200, потом ответил 404. Но общее состояние всё то же, файл же уже удалён.
    
    В ансибле есть идемпотентность в модулях. Если я скажу создать файл при первом запуске он его создаст. При втором он увидит, что создано, и создавать не будет.
    
    Но может быть проблема например с распаковкой архива. Мы можем просто его распаковывать и распаковывать в какую-то директорию. Это уже ближе к неидемпотентному сценарию.
    
- Ответ в контексте ансибла
    
    **Идемпотентность** - это такая характеристика действия, согласно которой повторное выполнение этого действия будет давать тот же результат, что и первый запуск.
    
    В контексте систем управления конфигурациями это означает, что сценарии, написанные с соблюдением такого подхода, не изменят, не сломают и не выдадут ошибок на управляемом хосте при повторном запуске.
    
    Например, нам нужно добавить пользователя на хост, для bash это будет выглядеть так:
    
    ```yaml
    useradd newuser -ms /bin/bash
    ```
    
    Но если мы запустим команду второй раз, то получим ошибку
    
    ```yaml
    useradd newuser -ms /bin/bash
    useradd: user 'newuser' already exists
    ```
    
    Поэтому нам нужно дополнительно добавлять проверку, например так:
    
    ```yaml
    id newuser || useradd newuser -ms /bin/bash
    ```
    
    В случае Ansible мы только декларируем состояние, например:
    
    ```yaml
    - hosts: localhost
      gather_facts: no
      tasks:
        - user:
            name: newuser
            shell: /bin/bash
            state: present
    ```
    
    При первом запуске плейбук Ansible ответит:
    
    ```yaml
    TASK [user] ***
    changed: [localhost] => {
      "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python3"
      },
      "changed": true,
      "comment": "",
      "create_home": true,
      "group": 1001,
      "home": "/home/newuser",
      "name": "newuser",
      "shell": "/bin/bash",
      "state": "present",
      "system": false,
      "uid": 1001
    }
    ```
    
    При повторном:
    
    ```yaml
    TASK [user] ***
    ok: [localhost] => {
      "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python3"
      },
      "append": false,
      "changed": false,
      "comment": "",
      "group": 1001,
      "home": "/home/newuser",
      "move_home": false,
      "name": "newuser",
      "shell": "/bin/bash",
      "state":
      "present",
      "uid": 1001
    }
    ```
    
    Обратите внимание, что статус задания сменился с `changed` на `ok` и повторный запуск вернул значение `"changed": false` 
    
    Таким образом, сценарии, написанные с учетом идемпотентности, реализуют ту самую декларативность в описании состояния инфраструктуры, а инфраструктура соответствует состоянию, описанному в коде нашего скрипта.
    
    Это и есть **IaС - Infrastructure as Code - инфраструктура как код**
    
---

### Для чего нужны хендлеры, handlers?

- Ответ
    
    Задачу можно дополнить обработчиками, которые будут срабатывать, если задача была выполнена успешно.
    
    Например, мы установили nginx и хотим его запустить
    
    ```yaml
    ---
    - hosts: testbox
      sudo: yes
      tasks:
       - name: Install Nginx
         yum: pkg=nginx state=latest
         notify:
             - NGINX start
    
      handlers:
        - name: NGINX start
          service: name=nginx state=started
    ```
    
---

### В чем разница pull и push модели?

- Ответы
    
    **Pull**-модель преполагает, что управляемые хосты подтягивают инструкции с мастер-сервера.
    
    **Push**-модель реализует подход, когда инструкции по желанию или по событию доставляются с управляющего на управляемые хосты.
    
    Ansible чаще всего используется для push-модели управления, но умеет и pull-модель.
    
---
### Опишите основные примитивы Ansible

- Ответы
    
    **Инвентарь (Inventory)**
     - cписок хостов, может быть статичным в виде текcтового файла в формате `.ini` или динамическим в виде скрипта или плагина, который подгружает структуру данных из стороннего источника, например, Openstack API или база LDAP.
    
    ```
    $ cat hosts
    [web]
    nginx01
    nginx02
    nginx03
    
    [mysql]
    mysql01
    mysql02
    mysql03
    
    [prod:children]
    web
    mysql
    
    [devel]
    dev-nginx01
    dev-mysql01
    ```
    
    Данный пример описывает группы хостов web, mysql, prod и devel, группа prod наследует содержимое групп web и mysql.
    
    **Задание (Task)**
    
    - атомарная операция, выполняемая на управляемом хосте, например:
    
    ```yaml
    apt:
      package: nginx
      state: present
    ```
    
    Данный пример аналогичен команде `apt install nginx`
    
    **Сценарий (Play)** или **Плейбук (Playbook)**
    
    - сценарий или скрипт, содержащий одно или несколько заданий на выполнение, например:
    
    ```yaml
    $ cat prod-playbook.yml
    ---
    - hosts: nginx
      tasks:
        - apt:
            package: nginx
            state: present
        - shell: whoami
    ```
    
    **Роль (Role)**
    
    - более сложная абстракция, выглядит как структура директорий и файлов, которые описывают набор дефолтных переменных, зависимостей от других ролей, может содержать файлы и темплейты, содержит задания(Tasks).
    
    **Факты (Facts)**
    
    - структура данных, которая содержит информацию о хосте, например, версию дистрибутива, IP адреса и файловые системы. Ansible забирает эту информацию с хоста, и на нее можно ссылаться в коде плейбуков и ролей.
    
    Сбор фактов хоста занимает некоторое время, поэтому их можно кэшировать или отключить их сбор при выполнении плейбука.
    
---

### Отличие ansible и terraform 

- Ответ

    **Terraform** - Предназначен для представления инфраструктуры как код и автоматизации ее развертывания. 
    
    **Ansible** - Предназначен для автоматизации развертывания и конфигурации приложений.
    
    То есть Terraform используется что бы разворачивать инфраструктуру (виртуальные машины, сети, диски, и тп.).
    Ansible предназначен для работы с существующими ресурсами, чтобы устанавливать и настраивать окружение (программы, операционные системы) на этих виртуалках.

    Нюансы:
     Terraform отслеживает состояние и делает инкрементные изменения, что особенно полезно при работе с облачной инфраструктурой.
     Ansible не управляет состоянием, и каждая задача считается независимой.

     Нужно понимать, что это инструменты. И в ряде случаев с помощью Ansible равзвернуть инфраструктуру всё таки можно. 
     Как и для терраформа написать провайдер, который будет делать что-то свое. Вопрос лишь в применимости инструментов. 

---


## KUBERNETES

### Что такое kubernetes?

- Ответ
    
    Это система управления кластерами контейнеров linux.
    
    Кубер может запускать и управлять контейнерами на большом количестве хостов. А также имеет возможность это всё размещать и реплицировать.
    
---

### Какую проблему решает kubernetes?

- Ответ
    1. Масштабирование и запуск контейнеров на большом количестве хостов
    2. Балансировка контейнеров между ними.
    
    Также у кубера есть высокоуровневый API для группирования, размещения и балансирования контейнеров.
    
- Какие задачи он решает
    - Автоматизация инфраструктуры. Он развертывает приложения, откатывает.
    - Масштабирование приложения
    - Supervision - контролер, который мониторит состояние кластера. И сравнивает его состояние с требованиями, которые ему описали.
    - Service discovery - позволяет сервисы находить в автоматическом режиме.
    - Он решает вопросы, которые связаны с логгированием.
    - Решает вопросы с мониторингом и сбором метрик
    - CI\CD
    - Уменьшает vendor lock-in. Мы меньше зависимы от оборудования и провайдеров. Мы тут общаемся с апи кубернетеса. Он как черный ящик, которому мы говорим что делать. И он делает.
    
---

### Что такое minikube?

- Ответ
    
    Локальный кластер для знакомства с кубером, или для проверки каких-либо вещей.
    

### Приведи пример проблемы, которая упрощает работу именно с использованием кубернетеса?

- Ответ
    
    Например, у нас есть три машины. На них запущены контейнеры.
    
    И вдруг одна из машин встала с запущенными контейнерами. Или нужно машину перезапустить. 
    
    И контейнеры нужно переносить.
    
    В итоге нужно будет решать проблемы
    
    1. Контейнеры могут быть связаны, и они должны быть на одной ноде. Значит и перенести нужно на другую ноду их, сохранив эту связанность. Связанность - это использование общих данных. Или активное взаимодействие между собой.
    2. Контейнеры не могут “поместиться” на одном узле, и нужно думать а куда вот эти перевести и распределить
    3. При возвращении ноды в строй придётся возвращать все контейнеры. Снова нужно делать те же манипуляции.

---

### Что такое pod?

- Ответ
    
    Запрос на запуск одного или более контейнеров на одном узле.
    
    Также под это совокупность контейнеров, которые запускаются в ответ на запрос.
    
    Эти контейнеры разделяют доступ к ресурсам типа томов хранилища, и сетевой стек. И каждый под имеет свой собственный внутренний апи
    
    ![pod-img](https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled%2015.png)
    

---

### В чем разница между подом и контейнером?**

- Ответ
    
    Под это минимальная единица куба. В котором есть контейнеры. 
    
---

<img width="1472" height="1032" alt="image" src="https://github.com/user-attachments/assets/e9385aa8-cf9d-45e4-b618-8de383f7effc" />

Мастер управляет воркерами в одном кластере.

<img width="624" height="951" alt="image" src="https://github.com/user-attachments/assets/937ac61c-35fb-461c-a829-31df9cdfbc77" />

API Server - наш способ управления кластером (сюда идет запрос)

Controller Manager - управляющий кластером, у него есть план и все должны к нему стремиться(желаемое состояние (текущее состояние -> желаемое)) 

Scheduler - планируетя как расположить контейнеры на различных нодах кластера (смотрит на загруженность кластера и ее мощности)

etcd - хранилище данных (ключ - значение), хранит информацию о текущем состоянии кластера

<img width="616" height="785" alt="image" src="https://github.com/user-attachments/assets/0da8c330-2393-4696-9e92-81720635582e" />

kublet - общение с мастером, получает инфу что и как должно работать на конкретной ноде 

container runtime (исполняемая среда контейнера) - kublet дает команды об образах контейнеров, их остановке, запуске и управлении их ресурсов 

kube-proxy - отвечает за коммуникацию и балансировку внутренней сети 


контейнеры запускаются в POD'ах

---

### Что такое Volume

- Ответ
    
    Volume - это абстракция файлового хранилища.
    
    Решает следующие основные проблемы:
    
    - Файловая ситема контейнера существует только до его удаления или перезапуска
    - Некоторым контейнерам нужно общее пространство для хранения файлов, или для обращения к конфигурационным файлам.
    - Изолирует приложение от технологий хранения данных
    
    Живет только с подом

---  

### Что такое Helm

- Ответ
    
    Пакетный менеджер для кубера.
    Шаблонизатор для управления
    
    Пакет в helm это набор yml и tpl файлов.

    *.tpl файлы нужны для определения каких то функций
    который будут возвращать какие то параметры либо имена и тд
    в файле *.tpl ты с помощью ключевого слова define определяешь функцию
    а в самом хелм чарте с помощью include, вставляешь ее результат.
    Обычно используется для генерации labels, полных имен и тд.
   
---

### Что дает helm в кубе ?

- Ответ

    1. Версионирования.
    2. Шаблонизирование.
    3. Удобство развертывания инфраструктуры на разные контура.
    4. Более подконтрольная работа с конкретной разворачиваемой инфраструктурой.
    5. Возможность подтягивать зависимости. Допустим  если у тебя хелм чарт 
       зависит от другого хелм чарта, ты можешьб либо в самом Chart.yml 
       файле в директиве dependency прописать зависимотси, либо 
       в отдельном файле requirements.yml прописать все зависимости
       и перед раскаткой основного хелм чарта поднятнуть все зависимости командой 
       `helm dependency update`.


---


## GITLAB CI/CD

### Каковы ключевые компоненты GitLab CI/CD?

- Ответ
    - Ключевые компоненты включают в себя:

    **Файл .gitlab-ci.yml:**
    - Определяет конфигурацию конвейера
    - Содержит описание всех job, stages, переменных и правил
    - Должен находиться в корне репозитория

    **Runners:**
    - Выполняют задания (jobs)
    - Могут быть shared (общие), group (групповые) или specific (проектные)
    - Поддерживают различные executors (Docker, Shell, Kubernetes и др.)

    **Задания (Jobs) и этапы (Stages):**
    - **Jobs** - отдельные задачи с командами для выполнения
    - **Stages** - группируют jobs и определяют порядок их выполнения
    - Jobs в одном stage выполняются параллельно
    - Stages выполняются последовательно

    **Конвейеры (Pipelines):**
    - Автоматизируют рабочие процессы от написания кода до развертывания
    - Запускаются автоматически при push, merge request или по расписанию
    - Состоят из одного или нескольких stages

    **Пример базовой структуры:**

    ```yaml
    stages:
      - build
      - test
      - deploy

    variables:
      NODE_VERSION: "18"

    build_job:
      stage: build
      script:
        - npm install
        - npm run build
      artifacts:
        paths:
          - dist/

    test_job:
      stage: test
      script:
        - npm run test
      coverage: '/Coverage: \d+\.\d+%/'

    deploy_job:
      stage: deploy
      script:
        - npm run deploy
      only:
        - main
    ```

---

### Что такое before_script и after_script в GitLab CI/CD?/CD?

- Ответ
    - `before_script` - выполняет команды перед основным скриптом каждой job
    - `after_script` - выполняет команды после основного скрипта каждой job

    **Особенности использования:**

    **before_script:**
    - Выполняется в той же shell-сессии, что и script
    - Если завершается с ошибкой, job помечается как failed
    - Переменные, установленные здесь, доступны в script

    **after_script:**
    - Выполняется в отдельной shell-сессии
    - Всегда выполняется, даже если script завершился с ошибкой
    - Переменные из script и before_script недоступны
    - Не влияет на статус job

    **Пример использования:**

    ```yaml
    job_example:
      before_script:
        - echo "Setting up environment"
        - export DATABASE_URL="test://localhost"
        - npm install
      script:
        - echo "Running main script"
        - npm run test
      after_script:
        - echo "Cleaning up"
        - docker stop test-container || true
        - rm -rf temp-files/

    # Глобальные before_script и after_script для всех job
    default:
      before_script:
        - echo "Global setup"
      after_script:
        - echo "Global cleanup"

    # Переопределение глобальных настроек в конкретной job
    custom_job:
      before_script:
        - echo "Custom setup only"
      script:
        - echo "Custom script"
      # after_script наследуется от default
    ```

---

### У вас есть 5 проектов на одном языке программирования. Как организовать пайплайны, чтобы избежать дублирования конфигурации?

- Ответ
    - Для избежания дублирования конфигурации используйте следующие подходы:
        1. **Создание общих шаблонов** - вынесите повторяющиеся задачи (`build`, `test`, `lint`) в отдельный YAML-файл
        2. **Использование `include`** - подключайте общие конфигурации в проектах
        3. **Применение шаблонов** - используйте `extends`, `rules`, переменные окружения

    **Пример структуры:**

    ```yaml
    # common-templates.yml
    .build_template:
      stage: build
      script:
        - npm install
        - npm run build
      artifacts:
        paths:
          - dist/

    .test_template:
      stage: test
      script:
        - npm run test
      coverage: '/Coverage: \d+\.\d+%/'

    # В каждом проекте .gitlab-ci.yml
    include:
      - project: 'templates/ci-templates'
        file: 'common-templates.yml'

    build_job:
      extends: .build_template

    test_job:
      extends: .test_template
    ```

---

### Как запускать тесты только при создании merge request?

- Ответ
    - Используйте директиву `rules` с условием проверки источника пайплайна:

    ```yaml
    test_job:
      stage: test
      script:
        - echo "Running tests for merge request"
        - npm run test
      rules:
        - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    ```

    **Дополнительные варианты контроля:**

    ```yaml
    # Запуск только для MR в определенную ветку
    test_mr_to_main:
      script:
        - npm run test
      rules:
        - if: '$CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == "main"'

    # Запуск при изменении определенных файлов
    test_on_changes:
      script:
        - npm run test
      rules:
        - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
          changes:
            - "src/**/*"
            - "tests/**/*"
    ```

    **Документация:** https://docs.gitlab.com/ci/pipelines/merge_request_pipelines/

---

### Если в before_script переопределить переменную, будет ли она доступна в script?pt`?

- Ответ
    - Да, переменная будет доступна. Все секции `before_script`, `script` и `after_script` выполняются в рамках одной shell-сессии в пределах одной job.

    **Пример:**

    ```yaml
    job_with_variable:
      variables:
        ORIGINAL_VAR: "initial_value"
      before_script:
        - export MODIFIED_VAR="modified_in_before_script"
        - echo "MODIFIED_VAR in before_script: $MODIFIED_VAR"
      script:
        - echo "MODIFIED_VAR in script: $MODIFIED_VAR"  # Будет доступна
        - echo "ORIGINAL_VAR: $ORIGINAL_VAR"           # Тоже доступна
      after_script:
        - echo "MODIFIED_VAR in after_script: $MODIFIED_VAR"  # И здесь тоже
    ```

    **Важно:** Переменные, определенные в одной job, не передаются в другие job без использования артефактов или других механизмов.

---

### Какие существуют способы контроля запуска job в GitLab CI?

- Ответ
    - Существует несколько механизмов для контроля выполнения job:

    **1. Rules (рекомендуемый способ)**
    
    Наиболее гибкий и современный подход:

    ```yaml
    deploy_job:
      script:
        - echo "Deploying to production"
      rules:
        - if: '$CI_COMMIT_BRANCH == "main"'
        - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
          when: manual
        - when: never
    ```

    **2. Only/Except (устаревший)**
    
    ```yaml
    build_job:
      script:
        - echo "Building application"
      only:
        - main
        - develop
      except:
        - tags
    ```

    **3. Встроенные переменные**
    - `$CI_COMMIT_BRANCH` - название текущей ветки
    - `$CI_PIPELINE_SOURCE` - источник запуска пайплайна
    - `$CI_COMMIT_TAG` - тег коммита
    - `$CI_MERGE_REQUEST_TARGET_BRANCH_NAME` - целевая ветка MR

    **4. Changes и Paths**
    
    ```yaml
    test_frontend:
      script:
        - npm run test
      rules:
        - changes:
            - "frontend/**/*"
            - "package.json"
    ```

    **5. Manual jobs**
    
    ```yaml
    deploy_production:
      script:
        - echo "Deploying to production"
      when: manual
      only:
        - main
    ```

    **6.Через `when`**
    - `when: always` - всегда выполнять
    - `when: on_success` - только при успехе предыдущих job (по умолчанию)
    - `when: on_failure` - только при провале предыдущих job
    - `when: manual` - запуск вручную
    - `when: never` - никогда не выполнять

---

## GIT

### Чем `merge` отличается от `rebase`?

- Ответ
    - `git merge` - выполняет слияние коммитов из одной ветки в другую. В этом процессе изменяется только целевая ветка. История исходных веток остается неизменной.
        
        ![https://github.com/rmntrvn/adm_linux_ops_questions/raw/master/questions/imgs/git-merge.png](https://github.com/rmntrvn/adm_linux_ops_questions/raw/master/questions/imgs/git-merge.png)
        
        *Преимущества*:
        
        1. Простота,
        2. Сохраняет полную историю и хронологический порядок,
        3. Поддерживает контекст ветки.
        
        *Недостатки*:
        
        1. История коммитов может быть заполнена (загрязнена) множеством коммитов,
        2. Отладка с использованием git bisect может стать сложнее.
    - `git rebase` - сжимает все изменения в один патч. Затем интегрирует патч в целевую ветку. В отличии от *merge*, *rebase* перезаписывает историю, потому что она передаётся завершенную работу из одной ветки в другую. В процессе устраняется нежелательная история.
        
        ![https://github.com/rmntrvn/adm_linux_ops_questions/raw/master/questions/imgs/git-rebase.png](https://github.com/rmntrvn/adm_linux_ops_questions/raw/master/questions/imgs/git-rebase.png)
        
        *Преимущества*:
        
        1. Упрощает потенциально сложную историю,
        2. Упрощение манипуляций с единственным коммитом,
        3. Избежание слияния коммитов в занятых репозиториях и ветках,
        4. Очищает промежуточные коммиты, делая их одним коммитом, что полезно для DevOps команд.
        
        *Недостатки*:
        
        1. Сжатие фич до нескольких коммитов может скрыть контекст
        2. Перемещение публичных репозиториев может быть опасным при работе в команде,
        3. Появляется больше работы,
        4. Для восстановления с удаленными ветками требуется принудительный пуш. Это приводит к обновлению всех веток, имеющих одно и то же имя, как локально, так и удаленно.
---

### Когда нужно использовать `merge`, когда `rebase`?

- Ответ
    
    Предназначение этих команд git – интеграция изменений из одной ветки в другую, но делают они это по-разному.
    
    Предположим, у вас сложилась такая ситуация:
    
    ```
    A <- B <- C    [master]
    ^
     \
      D <- E       [branch]
    ```
    
    После обычного мержа репозиторий будет выглядеть так:
    
    ```
    A <- B <- C
    ^         ^
     \         \
      D <- E <- F
    ```
    
    А после `git rebase`– так:
    
    ```
    A <- B <- C <- D <- E
    ```
    
    Rebase указывает на то, что коммиты нужно буквально перенести со старого места на новое.
    
    Что выбрать?
    
    - Если вы сомневаетесь, то используйте обычное слияние.
    - Выбор между merge и rebase обусловлен тем, какой вы хотите видеть историю коммитов: линейной или ветвящейся.
    
    Учитывайте следующие факторы:
    
    1. Если ветка, в которую вы хотите внести изменения доступна для других разработчиков (например, в open source проекте), не используйте rebase. Эта команда удаляет ветку целиком и приводит к рассинхронизации копий
    репозиториев.
    2. Представляет ли исходная ветка ценность? Некоторые команды работают
    по принципу «одна функция – одна ветка», при этом ветка идентифицирует
    последовательность коммитов. В модели «один разработчик – одна ветка» в
    этом нет особой необходимости, так как автор коммита известен.
    3. Не захотите ли вы вдруг отменить слияние? Возврат rebase значительно затруднен по сравнению с обычным слиянием, а иногда даже невозможен.

---

### Чем отличается git pull и git fetch

- Ответ
    
    При использовании `pull`, git пытается сделать всё за вас. Он сливает любые внесённые коммиты в ветку, в которой вы сейчас работаете. 
    
    Команда `pull` автоматически сливает коммиты, не давая вам сначала просмотреть их. Если вы не пристально следите за ветками, выполнение этой команды может привести к частым конфликтам.
    
    При использовании `fetch`, git собирает все коммиты из целевой ветки, которых нет в текущей ветке, и сохраняет их в локальном репозитории. Однако он не сливает их в текущую ветку
    
- Краткий ответ
    
    git pull — это, по сути, команда git fetch, после которой сразу же следует git merge.
    
    Команда git fetch получает изменения с сервера и сохраняет их в каталог refs/remotes/. Это действие (fetch) не влияет на локальные ветки и текущие изменения, просто изменения с удаленного сервера скачиваются в директорию локального репозитария.
    
---

### Какие пратики работы с гитом вы знаете? Форки

- Ответ
    
    Работа через форки принципиально отличается от других популярных методов организации командной разработки. Вместо того чтобы использовать один серверный репозиторий в качестве центральной кодовой базы, здесь каждый разработчик получает свой собственный репозиторий. Чаще всего эта модель применяется в общедоступных open source проектах.
    
    Основное преимущество forking workflow заключается в том, что все изменения вносятся без загрязнения истории проекта. Разработчики делают push в собственные репозитории, а доступ к центральному есть только у менеджера.
    
    Когда обновление готово к интеграции, программист делает pull-запрос в главный репозиторий, а менеджер одобряет и вносит его.

    В принципе какие сть форки:
     - central workflow - когда все сразу с мастер пушится 
     - trunk based - есть 3 ветки: мастер, дев, фьечер.
       основные особенности такой разработки что ветки живут недолго, что есть флаги которыми можно выключить и включать фичи, код в мастере почти всегда готов к деплою даже если в нем есть недоработанные фичи, постоянное код ревью кода (ревью пару минут на микро изменения и мерж)
     - gitflow 

    ![по подробнее почитать про trunk based development](https://habr.com/ru/articles/519314/)
    
---

### Что такое GitFlow?

- Ответ
    
    [Модель gitflow](https://proglib.io/p/git-github-gitflow/) использует две параллельные «долгие» ветки для хранения истории проекта: master и develop.
    
    - **Master** – это полностью готовое к релизу состояние со всеми пройденными тестами.
        - **Hotfix** – ветки обслуживания, или хотфиксы, которые
        используются для быстрых патчей. Они очень похожи на feature, но вместо
        develop-ветки базируются на master.
    - **Develop** – ветка, в которой объединяются и тестируются все отдельные разработки. После прохождения проверок они отправляются в master.
        - **Feature** – отдельная ветка для каждой новой функциональности, изменения из которой отправляются в develop.
    
   ![gitflow-img](https://github.com/Swfuse/devops-interview/blob/main/imgs/Untitled%2022.png)


---

### Ошибки случаются — как их откатывать?

Иногда мы коммитим не тот файл, или хотим отменить изменения. Git предлагает гибкие инструменты для отката:

git reset — откат к предыдущему состоянию, меняет HEAD и индекс

git revert — отмена коммита путём создания нового коммита с противоположными изменениями

git checkout / git restore — откат отдельных файлов

**Важно понимать разницу: reset — «переписывает историю», а revert — «создаёт новую».**


